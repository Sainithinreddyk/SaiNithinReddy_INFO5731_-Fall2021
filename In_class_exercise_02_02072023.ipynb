{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sainithinreddyk/SaiNithinReddy_INFO5731_-Spring2023/blob/main/In_class_exercise_02_02072023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0X9x-EI7Nj4"
      },
      "source": [
        "## The second In-class-exercise (02/07/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e0FBiLu7Nj8"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFUu9RWc7Nj9"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f-knz29Q7Nj-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f3a06eb2-2885-45c1-9123-a0e9321a65e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\n\\nNowadays Machine Learning is booming and many people are trying to get into that field they are finding it a bit difficult to find the correct job that matches their profile and in my opinion times job \\nis updating the requirement of the companies and based on the eligibility we can choose the appropriate one and get into that.\\n\\nI have collected the data from the times job site and sorted as no experience and there are almost 50k suggestions and I have taken the intial 1234 suggestionas and all are them are from Walmart\\nand based on the skill set and publishesd time I have sorted and collected the data.\\n\\nAnd now using the beautiful soup I have gathered the information from \\nURL: https://www.timesjobs.com/candidate/job-search.html?from=submit&actualTxtKeywords=Machine%20Learning&searchBy=0&rdoOperator=OR&searchType=personalizedSearch&luceneResultSize=1234&postWeek=60&txtKeywords=machine%20learning&pDate=I&sequence=11&startPage=11\\nBy inspecting I have obtained the information of skill set, company name and published data and finally data is obatained in the form of csv.\\n\\nThere is no limit for the data because if the job requirement is high the chances of choosing will also be more\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "Nowadays Machine Learning is booming and many people are trying to get into that field they are finding it a bit difficult to find the correct job that matches their profile and in my opinion times job \n",
        "is updating the requirement of the companies and based on the eligibility we can choose the appropriate one and get into that.\n",
        "\n",
        "I have collected the data from the times job site and sorted as no experience and there are almost 50k suggestions and I have taken the intial 1234 suggestionas and all are them are from Walmart\n",
        "and based on the skill set and publishesd time I have sorted and collected the data.\n",
        "\n",
        "And now using the beautiful soup I have gathered the information from \n",
        "URL: https://www.timesjobs.com/candidate/job-search.html?from=submit&actualTxtKeywords=Machine%20Learning&searchBy=0&rdoOperator=OR&searchType=personalizedSearch&luceneResultSize=1234&postWeek=60&txtKeywords=machine%20learning&pDate=I&sequence=11&startPage=11\n",
        "By inspecting I have obtained the information of skill set, company name and published data and finally data is obatained in the form of csv.\n",
        "\n",
        "There is no limit for the data because if the job requirement is high the chances of choosing will also be more\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iimd_fP17NkA"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mHIYsFFC7NkA"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "#Intially I have loaded all the necessary libraries\n",
        "\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Intially I have loaded the empty list to append based on the company name, skill set and published time\n",
        "l=[]\n",
        "#I have converted the url into Beautiful Spup and checked how the format is \n",
        "#As the runtime is more I have taken only intial 1000 jobs to meet the requiremnt and we need more suggestions we can directly replace the results size with the required number and get the nnedful\n",
        "for i in range(0,10): \n",
        "    url = requests.get('https://www.timesjobs.com/candidate/job-search.html?from=submit&actualTxtKeywords=Machine%20Learning&searchBy=0&rdoOperator=OR&searchType=personalizedSearch&luceneResultSize=1234&postWeek=60&txtKeywords=machine%20learning&pDate=I&sequence=11&startPage=11').text\n",
        "    soup = bs(url,'lxml')\n",
        "    #print(soup)\n",
        "    job_find= soup.find_all('li',class_='clearfix job-bx wht-shd-bx')\n",
        "    #print(job_find)\n",
        "#From all the suggestions I have sorted bases on the company name, skill set and published time and I have appended in the empty list\n",
        "for i in job_find:\n",
        "    company_name = soup.find('h3',class_='joblist-comp-name').text.replace(' ','')\n",
        "    skill_set = soup.find('span',class_='srp-skills').text.replace(' ','')\n",
        "    Published_time = soup.find('span',class_='sim-posted').text\n",
        "    l.append([company_name,skill_set,Published_time])\n",
        "#Now I have created the data frame and added company name, skillset and Published time\n",
        "df=pd.DataFrame(l,columns=['COMPANY_NAME','SKILLSET','PUBLISHED_TIME']) \n",
        "#Now by printing the data frame we can get the Intial 1000 jobs in the field of ML and I have taken 1234 samples\n",
        "#print(df)\n",
        "print(\"The length of Machine Learning Jobs from Times Job:\",len(df))\n",
        "#Here I have converted the data frame into csv\n",
        "df.to_csv('ML_Jobs.csv',index= False ,header = False)"
      ],
      "metadata": {
        "id": "zdwdbVE8LSs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c9e202-4c4c-467a-c603-0bf422a75d84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of Machine Learning Jobs from Times Job: 1234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVHTdr7J7NkB"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zpgw7VaI7NkB"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "#Intially I have imported all the necessary libraries\n",
        "import json \n",
        "import urllib.request as request\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To collect the article I have choosen semantic scholar and with the keyword as Information Retrival and fields as mentioned in the question title, venue, year, author, abstract I have gathered the information\n",
        "with request.urlopen('https://api.semanticscholar.org/graph/v1/paper/search?query=information+retrieval&offset=0&limit=99&fields=title,venue,year,authors,abstract') as file_read:\n",
        "    url = file_read.read() #To read the web\n",
        "    soup=bs(url)\n",
        "    #print(soup.pretiffy())\n",
        "    #Here I am going to print the text with the required fields\n",
        "    print(bs(url).p.text)\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP_Q297JjvRV",
        "outputId": "51962bc0-bf50-46ac-bddf-8c0fb022dd60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"total\": 8778006, \"offset\": 0, \"next\": 99, \"data\": [{\"paperId\": \"5f3b50c6c826ad105163b09d53e1eb498a4b3994\", \"title\": \"Introduction to Information Retrieval\", \"abstract\": \"Introduction To Information Retrieval Overdrive Digital. Introduction To Information Retrieval. Introduction To Information Retrieval Putao Ufcg. Introduction To Information Retrieval Arbeitsbereiche. Introduction To Information Retrieval. Introduction To Information Retrieval Stanford Nlp Group. Introduction To Information Retrieval Cs Ucr Edu. Introduction To Information Retrieval By Christopher D. Introduction To Information Retrieval Book. Information Retrieval The Mit Press. Introduction Information Retrieval Uvm. Information Retrieval Lmu Munich. Introduction To Information Retrieval Stanford University. Introduction To Information Retrieval. Introduction To Information Retrieval Amp Models Slideshare. Introduction To Information Retrieval Kangwon Ac Kr. Information Retrieval. Introduction To Information Retrieval Assets. Introduction To Information Retrieval. Introduction To Information Retrieval\", \"venue\": \"J. Assoc. Inf. Sci. Technol.\", \"year\": 2010, \"authors\": [{\"authorId\": \"1803434\", \"name\": \"R. Larson\"}]}, {\"paperId\": \"807600ef43073cd9c59d4208ee710e90cf14efa8\", \"title\": \"BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models\", \"abstract\": \"Existing neural information retrieval (IR) models have often been studied in homogeneous and narrow settings, which has considerably limited insights into their out-of-distribution (OOD) generalization capabilities. To address this, and to facilitate researchers to broadly evaluate the effectiveness of their models, we introduce Benchmarking-IR (BEIR), a robust and heterogeneous evaluation benchmark for information retrieval. We leverage a careful selection of 18 publicly available datasets from diverse text retrieval tasks and domains and evaluate 10 state-of-theart retrieval systems including lexical, sparse, dense, late-interaction and re-ranking architectures on the BEIR benchmark. Our results show BM25 is a robust baseline and re-ranking and late-interaction based models on average achieve the best zeroshot performances, however, at high computational costs. In contrast, dense and sparse-retrieval models are computationally more efficient but often underperform other approaches, highlighting the considerable room for improvement in their generalization capabilities. We hope this framework allows us to better evaluate and understand existing retrieval systems, and contributes to accelerating progress towards better robust and generalizable systems in the future. BEIR is publicly available at https://github.com/UKPLab/beir.\", \"venue\": \"NeurIPS Datasets and Benchmarks\", \"year\": 2021, \"authors\": [{\"authorId\": \"47583894\", \"name\": \"Nandan Thakur\"}, {\"authorId\": \"2959414\", \"name\": \"Nils Reimers\"}, {\"authorId\": \"1404060894\", \"name\": \"Andreas Ruckl'e\"}, {\"authorId\": \"153257123\", \"name\": \"Abhishek Srivastava\"}, {\"authorId\": \"69033154\", \"name\": \"Iryna Gurevych\"}]}, {\"paperId\": \"806c2c4327a31fded64a5d673ab82b133194c234\", \"title\": \"Introduction to information retrieval\", \"abstract\": \"Class-tested and coherent, this textbook teaches classical and web information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. It gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Slides and additional exercises (with solutions for lecturers) are also available through the book's supporting website to help course instructors prepare their lectures.\", \"venue\": \"\", \"year\": 2008, \"authors\": [{\"authorId\": \"144783904\", \"name\": \"Christopher D. Manning\"}, {\"authorId\": \"145503401\", \"name\": \"P. Raghavan\"}, {\"authorId\": \"144418438\", \"name\": \"Hinrich Sch\\u00fctze\"}]}, {\"paperId\": \"49af3e80343eb80c61e727ae0c27541628c7c5e2\", \"title\": \"Introduction to Modern Information Retrieval\", \"abstract\": \"Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd introduction to modern information retrieval as the choice of reading, you can find here.\", \"venue\": \"\", \"year\": 1983, \"authors\": [{\"authorId\": \"1797808\", \"name\": \"G. Salton\"}, {\"authorId\": \"144321599\", \"name\": \"M. McGill\"}]}, {\"paperId\": \"72c58a58ba1684dc8337c8e64e0b5dacfc94499e\", \"title\": \"Information Retrieval\", \"abstract\": null, \"venue\": \"Lecture Notes in Computer Science\", \"year\": 2018, \"authors\": [{\"authorId\": \"32293755\", \"name\": \"A. Dekhtyar\"}]}, {\"paperId\": \"d69c0ed04ecc852e8c921900d3e7967f74f81263\", \"title\": \"Pyserini: A Python Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations\", \"abstract\": \"Pyserini is a Python toolkit for reproducible information retrieval research with sparse and dense representations. It aims to provide effective, reproducible, and easy-to-use first-stage retrieval in a multi-stage ranking architecture. Our toolkit is self-contained as a standard Python package and comes with queries, relevance judgments, pre-built indexes, and evaluation scripts for many commonly used IR test collections. We aim to support, out of the box, the entire research lifecycle of efforts aimed at improving ranking with modern neural approaches. In particular, Pyserini supports sparse retrieval (e.g., BM25 scoring using bag-of-words representations), dense retrieval (e.g., nearest-neighbor search on transformer-encoded representations), as well as hybrid retrieval that integrates both approaches. This paper provides an overview of toolkit features and presents empirical results that illustrate its effectiveness on two popular ranking tasks. Around this toolkit, our group has built a culture of reproducibility through shared norms and tools that enable rigorous automated testing.\", \"venue\": \"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\", \"year\": 2021, \"authors\": [{\"authorId\": \"145580839\", \"name\": \"Jimmy J. Lin\"}, {\"authorId\": \"2461713\", \"name\": \"Xueguang Ma\"}, {\"authorId\": \"122045993\", \"name\": \"Sheng-Chieh Lin\"}, {\"authorId\": \"2109723027\", \"name\": \"Jheng-Hong Yang\"}, {\"authorId\": \"1816753042\", \"name\": \"Ronak Pradeep\"}, {\"authorId\": \"143744603\", \"name\": \"Rodrigo Nogueira\"}, {\"authorId\": \"1759787\", \"name\": \"D. Cheriton\"}]}, {\"paperId\": \"5fc5c5a4e489e781de434567d946e6eb65c44f60\", \"title\": \"Learning to rank for information retrieval\", \"abstract\": null, \"venue\": \"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\", \"year\": 2009, \"authors\": [{\"authorId\": \"2110264337\", \"name\": \"Tie-Yan Liu\"}]}, {\"paperId\": \"4cc5f709c372e4e87e46809c0830cac5cdaa0e40\", \"title\": \"Meeting the review family: exploring review types and associated information retrieval requirements.\", \"abstract\": \"BACKGROUND AND OBJECTIVES\\nThe last decade has witnessed increased recognition of the value of literature reviews for advancing understanding and decision making. This has been accompanied by an expansion in the range of methodological approaches and types of review. However, there remains uncertainty over definitions and search requirements beyond those for the 'traditional' systematic review. This study aims to characterise health related reviews by type and to provide recommendations on appropriate methods of information retrieval based on the available guidance.\\n\\n\\nMETHODS\\nA list of review types was generated from published typologies and categorised into 'families' based on their common features. Guidance on information retrieval for each review type was identified by searching pubmed, medline and Google Scholar, supplemented by scrutinising websites of review producing organisations.\\n\\n\\nRESULTS\\nForty-eight review types were identified and categorised into seven families. Published guidance reveals increasing specification of methods for information retrieval; however, much of it remains generic with many review types lacking explicit requirements for the identification of evidence.\\n\\n\\nCONCLUSIONS\\nDefining review types and utilising appropriate search methods remain challenging. By familiarising themselves with a range of review methodologies and associated search methods, information specialists will be better equipped to select suitable approaches for future projects.\", \"venue\": \"Health Information and Libraries Journal\", \"year\": 2019, \"authors\": [{\"authorId\": \"35333489\", \"name\": \"A. Sutton\"}, {\"authorId\": \"145247460\", \"name\": \"M. Clowes\"}, {\"authorId\": \"121377785\", \"name\": \"L. Preston\"}, {\"authorId\": \"2057603300\", \"name\": \"A. Booth\"}]}, {\"paperId\": \"bead8973ff87831f7ee41c5adda777f6021cdcea\", \"title\": \"IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models\", \"abstract\": \"This paper provides a unified account of two schools of thinking in information retrieval modelling: the generative retrieval focusing on predicting relevant documents given a query, and the discriminative retrieval focusing on predicting relevancy given a query-document pair. We propose a game theoretical minimax game to iteratively optimise both models. On one hand, the discriminative model, aiming to mine signals from labelled and unlabelled data, provides guidance to train the generative model towards fitting the underlying relevance distribution over documents given the query. On the other hand, the generative model, acting as an attacker to the current discriminative model, generates difficult examples for the discriminative model in an adversarial way by minimising its discrimination objective. With the competition between these two models, we show that the unified framework takes advantage of both schools of thinking: (i) the generative model learns to fit the relevance distribution over documents via the signals from the discriminative model, and (ii) the discriminative model is able to exploit the unlabelled data selected by the generative model to achieve a better estimation for document ranking. Our experimental results have demonstrated significant performance gains as much as 23.96% on Precision@5 and 15.50% on MAP over strong baselines in a variety of applications including web search, item recommendation, and question answering.\", \"venue\": \"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\", \"year\": 2017, \"authors\": [{\"authorId\": \"39055225\", \"name\": \"Jun Wang\"}, {\"authorId\": \"3469209\", \"name\": \"Lantao Yu\"}, {\"authorId\": \"2108309275\", \"name\": \"Weinan Zhang\"}, {\"authorId\": \"2087062414\", \"name\": \"Yu Gong\"}, {\"authorId\": \"50125871\", \"name\": \"Yinghui Xu\"}, {\"authorId\": \"2894465\", \"name\": \"Benyou Wang\"}, {\"authorId\": \"47243067\", \"name\": \"P. Zhang\"}, {\"authorId\": \"37510526\", \"name\": \"Dell Zhang\"}]}, {\"paperId\": \"47354d4d1915ae3d286d401005ba8a44af7d1fa5\", \"title\": \"A Deep Look into Neural Ranking Models for Information Retrieval\", \"abstract\": null, \"venue\": \"Information Processing & Management\", \"year\": 2019, \"authors\": [{\"authorId\": \"1777025\", \"name\": \"J. Guo\"}, {\"authorId\": \"7888704\", \"name\": \"Yixing Fan\"}, {\"authorId\": \"48537499\", \"name\": \"Liang Pang\"}, {\"authorId\": \"49576068\", \"name\": \"Liu Yang\"}, {\"authorId\": \"144922928\", \"name\": \"Qingyao Ai\"}, {\"authorId\": \"2499986\", \"name\": \"Hamed Zamani\"}, {\"authorId\": \"1748036\", \"name\": \"Chen Wu\"}, {\"authorId\": \"144456145\", \"name\": \"W. Bruce Croft\"}, {\"authorId\": \"1717004\", \"name\": \"Xueqi Cheng\"}]}, {\"paperId\": \"5f2cbe15668ed1365d3b3f34b13691673a75bfea\", \"title\": \"An Introduction to Neural Information Retrieval\", \"abstract\": \"Neural models have been employed in many Information Retrieval scenarios, including ad-hoc retrieval, recommender systems, multi-media search, and even conversational systems that generate answers in response to natural language questions. An Introduction to Neural Information Retrieval provides a tutorial introduction to neural methods for ranking documents in response to a query, an important IR task. The monograph provides a complete picture of neural information retrieval techniques that culminate in supervised neural learning to rank models including deep neural network architectures that are trained end-to-end for ranking tasks. In reaching this point, the authors cover all the important topics, including the learning to rank framework and an overview of deep neural networks. This monograph provides an accessible, yet comprehensive, overview of the state-of-the-art of Neural Information Retrieval.\", \"venue\": \"Foundations and Trends in Information Retrieval\", \"year\": 2018, \"authors\": [{\"authorId\": \"116506812\", \"name\": \"Bhaskar Mitra\"}, {\"authorId\": \"1703980\", \"name\": \"Nick Craswell\"}]}, {\"paperId\": \"4083ad1066cfa2ff0d65866ef4b011399d6873d1\", \"title\": \"Relevance feedback in information retrieval\", \"abstract\": null, \"venue\": \"\", \"year\": 1971, \"authors\": [{\"authorId\": \"134211067\", \"name\": \"J. Rocchio\"}]}, {\"paperId\": \"caa8b954566c9a97db0267b281d8a9843ecfac3d\", \"title\": \"Research Frontiers in Information Retrieval Report from the Third Strategic Workshop on Information Retrieval in Lorne (SWIRL 2018)\", \"abstract\": \"The purpose of the Strategic Workshop in Information Retrieval in Lorne is to explore the long-range issues of the Information Retrieval \\ufb01eld, to recognize challenges that are on \\u2013 or even over \\u2013 the horizon, to build consensus on some of the key challenges, and to disseminate the resulting information to the research community. The intent is that this description of open problems will help to inspire researchers and graduate students to address the questions, and will provide funding agencies data to focus and coordinate support for information retrieval research. structured and unstructured data sources and summarization of potentially long or complex answers in easily consumable units. more controlled than in open-ended interaction studies.\", \"venue\": \"\", \"year\": 2018, \"authors\": [{\"authorId\": \"1678892\", \"name\": \"N. Kando\"}, {\"authorId\": \"144448479\", \"name\": \"Alistair Moffat\"}, {\"authorId\": \"1732541\", \"name\": \"Falk Scholer\"}, {\"authorId\": \"1780364\", \"name\": \"Laurianne Sitbon\"}, {\"authorId\": \"48702898\", \"name\": \"Damiano Spina\"}, {\"authorId\": \"145980720\", \"name\": \"A. Trotman\"}, {\"authorId\": \"1746656\", \"name\": \"E. Voorhees\"}, {\"authorId\": \"49724730\", \"name\": \"Emine Yilmaz\"}, {\"authorId\": \"1692855\", \"name\": \"G. Zuccon\"}]}, {\"paperId\": \"c15679f1e190f559cb6123bfa058b5b8adc8c81e\", \"title\": \"Neural information retrieval: at the end of the early years\", \"abstract\": null, \"venue\": \"Information Retrieval Journal\", \"year\": 2018, \"authors\": [{\"authorId\": \"2766922\", \"name\": \"Kezban Dilek Onal\"}, {\"authorId\": \"39724818\", \"name\": \"Ye Zhang\"}, {\"authorId\": \"1757482\", \"name\": \"Ismail Seng\\u00f6r Alting\\u00f6vde\"}, {\"authorId\": \"2116361706\", \"name\": \"Md. Mustafizur Rahman\"}, {\"authorId\": \"2777963\", \"name\": \"P. Senkul\"}, {\"authorId\": \"51427469\", \"name\": \"Alexander Braylan\"}, {\"authorId\": \"40629713\", \"name\": \"B. Dang\"}, {\"authorId\": \"2116152139\", \"name\": \"Heng-Lu Chang\"}, {\"authorId\": \"2109554017\", \"name\": \"Henna Kim\"}, {\"authorId\": \"8493000\", \"name\": \"Quinten McNamara\"}, {\"authorId\": \"20888398\", \"name\": \"Aaron Angert\"}, {\"authorId\": \"145546504\", \"name\": \"Edward Banner\"}, {\"authorId\": \"3638684\", \"name\": \"Vivek Khetan\"}, {\"authorId\": \"40623583\", \"name\": \"Tyler McDonnell\"}, {\"authorId\": \"2080369972\", \"name\": \"A. T. Nguyen\"}, {\"authorId\": \"144742695\", \"name\": \"Dan Xu\"}, {\"authorId\": \"1912476\", \"name\": \"Byron C. Wallace\"}, {\"authorId\": \"1696030\", \"name\": \"M. de Rijke\"}, {\"authorId\": \"1747771\", \"name\": \"Matthew Lease\"}]}, {\"paperId\": \"3e37b7d4b60334ba083f60d69a73a8c251458d03\", \"title\": \"Research Frontiers in Information Retrieval: Report from the Third Strategic Workshop on Information Retrieval in Lorne (SWIRL 2018)\", \"abstract\": \"The purpose of the Strategic Workshop in Information Retrieval in Lorne is to explore the long-range issues of the Information Retrieval field, to recognize challenges that are on - or even over - the horizon, to build consensus on some of the key challenges, and to disseminate the resulting information to the research community. The intent is that this description of open problems will help to inspire researchers and graduate students to address the questions, and will provide funding agencies data to focus and coordinate support for information retrieval research.\", \"venue\": \"SIGF\", \"year\": 2018, \"authors\": [{\"authorId\": \"144159418\", \"name\": \"J. Culpepper\"}, {\"authorId\": \"145472333\", \"name\": \"Fernando Diaz\"}, {\"authorId\": \"1689089\", \"name\": \"M. Smucker\"}]}, {\"paperId\": \"61344ba701960b3d16e4792216e4b2ef9bc7c570\", \"title\": \"Anserini: Enabling the Use of Lucene for Information Retrieval Research\", \"abstract\": \"Software toolkits play an essential role in information retrieval research. Most open-source toolkits developed by academics are designed to facilitate the evaluation of retrieval models over standard test collections. Efforts are generally directed toward better ranking and less attention is usually given to scalability and other operational considerations. On the other hand, Lucene has become the de facto platform in industry for building search applications (outside a small number of companies that deploy custom infrastructure). Compared to academic IR toolkits, Lucene can handle heterogeneous web collections at scale, but lacks systematic support for evaluation over standard test collections. This paper introduces Anserini, a new information retrieval toolkit that aims to provide the best of both worlds, to better align information retrieval practice and research. Anserini provides wrappers and extensions on top of core Lucene libraries that allow researchers to use more intuitive APIs to accomplish common research tasks. Our initial efforts have focused on three functionalities: scalable, multi-threaded inverted indexing to handle modern web-scale collections, streamlined IR evaluation for ad hoc retrieval on standard test collections, and an extensible architecture for multi-stage ranking. Anserini ships with support for many TREC test collections, providing a convenient way to replicate competitive baselines right out of the box. Experiments verify that our system is both efficient and effective, providing a solid foundation to support future research.\", \"venue\": \"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\", \"year\": 2017, \"authors\": [{\"authorId\": \"2377909\", \"name\": \"Peilin Yang\"}, {\"authorId\": \"145344526\", \"name\": \"H. Fang\"}, {\"authorId\": \"145580839\", \"name\": \"Jimmy J. Lin\"}]}, {\"paperId\": \"b4465c399f2937990077eb57200ef7be6788e428\", \"title\": \"Private information retrieval\", \"abstract\": \"We describe schemes that enable a user to access k replicated copies of a database (k/spl ges/2) and privately retrieve information stored in the database. This means that each individual database gets no information on the identity of the item retrieved by the user. For a single database, achieving this type of privacy requires communicating the whole database, or n bits (where n is the number of bits in the database). Our schemes use the replication to gain substantial saving. In particular, we have: A two database scheme with communication complexity of O(n/sup 1/3/). A scheme for a constant number, k, of databases with communication complexity O(n/sup 1/k/). A scheme for 1/3 log/sub 2/ n databases with polylogarithmic (in n) communication complexity.\", \"venue\": \"Proceedings of IEEE 36th Annual Foundations of Computer Science\", \"year\": 1995, \"authors\": [{\"authorId\": \"1722541\", \"name\": \"B. Chor\"}, {\"authorId\": \"1738470\", \"name\": \"E. Kushilevitz\"}, {\"authorId\": \"1707322\", \"name\": \"Oded Goldreich\"}, {\"authorId\": \"1748838\", \"name\": \"M. Sudan\"}]}, {\"paperId\": \"7dcb1e6d6f6180659ff003784dc65c495086892b\", \"title\": \"The Capacity of Private Information Retrieval\", \"abstract\": \"In the private information retrieval (PIR) problem a user wishes to retrieve, as efficiently as possible, one out of K messages from N non-communicating databases (each holds all K messages) while revealing nothing about the identity of the desired message index to any individual database. The information theoretic capacity of PIR is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. For K messages and N databases, we show that the PIR capacity is (1 + 1/N + 1/N^2 + · · · + 1/N({K−1})^{−1}. A remarkable feature of the capacity achieving scheme is that if it is projected onto any subset of messages by eliminating the remaining messages, it also achieves the PIR capacity for that subset of messages.\", \"venue\": \"Global Communications Conference\", \"year\": 2016, \"authors\": [{\"authorId\": \"143844138\", \"name\": \"Hua Sun\"}, {\"authorId\": \"145486824\", \"name\": \"S. Jafar\"}]}, {\"paperId\": \"ba30c27884f6fd25e324538a42ef4a8a8952f353\", \"title\": \"Few-Shot Learning Through an Information Retrieval Lens\", \"abstract\": \"Few-shot learning refers to understanding new concepts from only a few examples. We propose an information retrieval-inspired approach for this problem that is motivated by the increased importance of maximally leveraging all the available information in this low-data regime. We define a training objective that aims to extract as much information as possible from each training batch by effectively optimizing over all relative orderings of the batch points simultaneously. In particular, we view each batch point as a `query' that ranks the remaining ones based on its predicted relevance to them and we define a model within the framework of structured prediction to optimize mean Average Precision over these rankings. Our method achieves impressive results on the standard few-shot classification benchmarks while is also capable of few-shot retrieval.\", \"venue\": \"NIPS\", \"year\": 2017, \"authors\": [{\"authorId\": \"2064782825\", \"name\": \"Eleni Triantafillou\"}, {\"authorId\": \"1804104\", \"name\": \"R. Zemel\"}, {\"authorId\": \"2422559\", \"name\": \"R. Urtasun\"}]}, {\"paperId\": \"9f8889ae93d2da09412fa862cc5895f40d114d5f\", \"title\": \"The Capacity of Private Information Retrieval From Coded Databases\", \"abstract\": \"We consider the problem of private information retrieval (PIR) over a distributed storage system. The storage system consists of  $N$  non-colluding databases, each storing an MDS-coded version of  $M$  messages. In the PIR problem, the user wishes to retrieve one of the available messages without revealing the message identity to any individual database. We derive the information-theoretic capacity of this problem, which is defined as the maximum number of bits of the desired message that can be privately retrieved per one bit of downloaded information. We show that the PIR capacity in this case is  $C=(1+{K}/{N}+{K^{2}}/{N^{2}}+\\\\cdots +{K^{M-1}}/{N^{M-1}})^{-1}=(1+R_{c}+R_{c}^{2}+\\\\cdots +R_{c}^{M-1})^{-1}=({1-R_{c}})/({1-R_{c}^{M}})$ , where  $R_{c}$  is the rate of the  $(N,K)$  MDS code used. The capacity is a function of the code rate and the number of messages only regardless of the explicit structure of the storage code. The result implies a fundamental tradeoff between the optimal retrieval cost and the storage cost when the storage code is restricted to the class of MDS codes. The result generalizes the achievability and converse results for the classical PIR with replicated databases to the case of MDS-coded databases.\", \"venue\": \"IEEE Transactions on Information Theory\", \"year\": 2016, \"authors\": [{\"authorId\": \"1995965\", \"name\": \"Karim A. Banawan\"}, {\"authorId\": \"1744394\", \"name\": \"S. Ulukus\"}]}, {\"paperId\": \"3f2f6772d96d972e3b2da5aaa8a0f2feefdf827f\", \"title\": \"Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer\", \"abstract\": null, \"venue\": \"\", \"year\": 1989, \"authors\": [{\"authorId\": \"1797808\", \"name\": \"G. Salton\"}]}, {\"paperId\": \"aad41c3828185b8d3e89b73867476b63ad0b9383\", \"title\": \"Neural Models for Information Retrieval\", \"abstract\": \"Neural ranking models for information retrieval (IR) use shallow or deep neural networks to rank search results in response to a query. Traditional learning to rank models employ machine learning techniques over hand-crafted IR features. By contrast, neural models learn representations of language from raw text that can bridge the gap between query and document vocabulary. Unlike classical IR models, these new machine learning based approaches are data-hungry, requiring large scale training data before they can be deployed. This tutorial introduces basic concepts and intuitions behind neural IR models, and places them in the context of traditional retrieval models. We begin by introducing fundamental concepts of IR and different neural and non-neural approaches to learning vector representations of text. We then review shallow neural IR methods that employ pre-trained neural term embeddings without learning the IR task end-to-end. We introduce deep neural networks next, discussing popular deep architectures. Finally, we review the current DNN models for information retrieval. We conclude with a discussion on potential future directions for neural IR.\", \"venue\": \"ArXiv\", \"year\": 2017, \"authors\": [{\"authorId\": \"116506812\", \"name\": \"Bhaskar Mitra\"}, {\"authorId\": \"1703980\", \"name\": \"Nick Craswell\"}]}, {\"paperId\": \"8a76b52ce9315b8ac1249248d128a777dc6cd9ea\", \"title\": \"Multi-Message Private Information Retrieval: Capacity Results and Near-Optimal Schemes\", \"abstract\": \"We consider the problem of multi-message private information retrieval (MPIR) from  $N$  non-communicating replicated databases. In MPIR, the user is interested in retrieving  $P$  messages out of  $M$  stored messages without leaking the identity of the retrieved messages. The information-theoretic sum capacity of MPIR  $C_{s}^{P}$  is the maximum number of desired message symbols that can be retrieved privately per downloaded symbol, where the symbols are defined over the same field. For the case  $P \\\\geq M/2$ , we determine the exact sum capacity of MPIR as  $C_{s}^{P}=1/(1+(M-P)/(PN))$ . The achievable scheme in this case is based on downloading MDS-coded mixtures of all messages. For  $P \\\\leq {M}/{2}$ , we develop lower and upper bounds for all  $M,P,N$ . These bounds match if the total number of messages  $M$  is an integer multiple of the number of desired messages  $P$ , i.e.,  $M/P \\\\in \\\\mathbb {N}$ . In this case,  $C_{s}^{P}=(1+1/N+\\\\cdots +1/N^{M/P-1})^{-1}$ , i.e.,  $C_{s}^{P}=(1-1/N)/(1-1/N^{M/P})$  for  $N>1$ , and  $C_{s}^{P}=P/M$  for  $N=1$ . The achievable scheme in this case generalizes the single-message capacity achieving scheme to have unbalanced number of stages per round of download. For all the remaining cases, the difference between the lower and upper bound is at most 0.0082, which occurs for  $M=5$ ,  $P=2$ ,  $N=2$ . Our results indicate that joint retrieval of desired messages is more efficient than successive use of single-message retrieval schemes even after considering the free savings that result from downloading undesired symbols in each single-message retrieval round.\", \"venue\": \"IEEE Transactions on Information Theory\", \"year\": 2017, \"authors\": [{\"authorId\": \"1995965\", \"name\": \"Karim A. Banawan\"}, {\"authorId\": \"1744394\", \"name\": \"S. Ulukus\"}]}, {\"paperId\": \"1ae2f8cad7133b1e111bdf72786415b65ee6ce93\", \"title\": \"The Capacity of Private Information Retrieval from Byzantine and Colluding Databases\", \"abstract\": \"We consider the problem of single-round private information retrieval (PIR) from  $N$  replicated databases. We consider the case when  $B$  databases are outdated (unsynchronized), or even worse, adversarial (Byzantine), and therefore, can return incorrect answers. In the PIR problem with Byzantine databases (BPIR), a user wishes to retrieve a specific message from a set of  $M$  messages with zero-error, irrespective of the actions performed by the Byzantine databases. We consider the  $T$ -privacy constraint in this paper, where any  $T$  databases can collude, and exchange the queries submitted by the user. We derive the information-theoretic capacity of this problem, which is the maximum number of correct symbols that can be retrieved privately (under the  $T$ -privacy constraint) for every symbol of the downloaded data. We determine the exact BPIR capacity to be  $C=(N-2B)/N \\\\cdot (1-T/(N-2B))/(1-(T/(N-2B))^{M})$ , if  $2B+T < N$ . This capacity expression shows that the effect of Byzantine databases on the retrieval rate is equivalent to removing  $2B$  databases from the system, with a penalty factor of  $(N-2B)/N$ , which signifies that even though the number of databases needed for PIR is effectively  $N-2B$ , the user still needs to access the entire  $N$  databases. The result shows that for the unsynchronized PIR problem, if the user does not have any knowledge about the fraction of the messages that are mis-synchronized, the single-round capacity is the same as the BPIR capacity. Our achievable scheme extends the optimal achievable scheme for the robust PIR (RPIR) problem to correct the errors introduced by the Byzantine databases as opposed to erasures in the RPIR problem. Our converse proof uses the idea of the cut-set bound in the network coding problem against adversarial nodes.\", \"venue\": \"IEEE Transactions on Information Theory\", \"year\": 2017, \"authors\": [{\"authorId\": \"1995965\", \"name\": \"Karim A. Banawan\"}, {\"authorId\": \"1744394\", \"name\": \"S. Ulukus\"}]}, {\"paperId\": \"947541d84e7588759d555702834b0fc4c709778a\", \"title\": \"The Capacity of T-Private Information Retrieval With Private Side Information\", \"abstract\": \"We consider the problem of  $T$ -Private Information Retrieval with private side information (TPIR-PSI). In this problem,  $N$  replicated databases store  $K$  independent messages, and a user, equipped with a local cache that holds  $M$  messages as side information, wishes to retrieve one of the other  $K-M$  messages. The desired message index and the side information must remain jointly private even if any  $T$  of the  $N$  databases collude. We show that the capacity of TPIR-PSI is  $\\\\left ({1+\\\\frac {T}{N}+\\\\cdots +\\\\left ({\\\\frac {T}{N}}\\\\right)^{K-M-1}}\\\\right)^{-1}$ . As a special case obtained by setting  $T=1$ , this result settles the capacity of PIR-PSI, an open problem previously noted by Kadhe et al. We also consider the problem of symmetric-TPIR with private side information (STPIR-PSI), where the answers from all  $N$  databases reveal no information about any other message besides the desired message. We show that the capacity of STPIR-PSI is  $1-\\\\frac {T}{N}$  if the databases have access to common randomness (not available to the user) that is independent of the messages, in an amount that is at least  $\\\\frac {T}{N-T}$  bits per desired message bit. Otherwise, the capacity of STPIR-PSI is zero.\", \"venue\": \"IEEE Transactions on Information Theory\", \"year\": 2017, \"authors\": [{\"authorId\": \"2117102362\", \"name\": \"Zhen Chen\"}, {\"authorId\": \"2108504099\", \"name\": \"Zhiying Wang\"}, {\"authorId\": \"145486824\", \"name\": \"S. Jafar\"}]}, {\"paperId\": \"4e0d7944d6af1e90c322d3c87b22cbae33df4eca\", \"title\": \"Private Information Retrieval With Side Information\", \"abstract\": \"We study the problem of Private Information Retrieval (PIR) in the presence of prior side information. The problem setup includes a database of  $K$  independent messages possibly replicated on several servers, and a user that needs to retrieve one of these messages. In addition, the user has some prior side information in the form of a subset of  $M$  messages, not containing the desired message and unknown to the servers. This problem is motivated by practical settings in which the user can obtain side information opportunistically from other users or has previously downloaded some messages using classical PIR schemes. The objective of the user is to retrieve the required message with downloading minimum amount of data from the servers while achieving information-theoretic privacy in one of the following two scenarios: (i) the user wants to protect jointly the identities of the demand and the side information; (ii) the user wants to protect only the identity of the demand, but not necessarily the side information. To highlight the role of side information, we focus first on the case of a single server (single database). In the first scenario, we prove that the minimum download cost is  $K-M$  messages, and in the second scenario it is  $\\\\lceil K/(M+1)\\\\rceil $  messages, which should be compared to  $K$  messages\\u2014the minimum download cost in the case of no side information. Then, we extend some of our results to the case of the database replicated on multiple servers. Our proof techniques relate PIR with side information to the index coding problem. We leverage this connection to prove converse results, as well as to design achievability schemes.\", \"venue\": \"IEEE Transactions on Information Theory\", \"year\": 2017, \"authors\": [{\"authorId\": \"1686542\", \"name\": \"S. Kadhe\"}, {\"authorId\": \"38743029\", \"name\": \"B. Garcia\"}, {\"authorId\": \"34512185\", \"name\": \"A. Heidarzadeh\"}, {\"authorId\": \"134711158\", \"name\": \"Salim el Rouayheb\"}, {\"authorId\": \"9039505\", \"name\": \"A. Sprintson\"}]}, {\"paperId\": \"ab5b6d74a464c7d7278a280bff967995edd6a907\", \"title\": \"Statistical biases in Information Retrieval metrics for recommender systems\", \"abstract\": null, \"venue\": \"Information Retrieval Journal\", \"year\": 2017, \"authors\": [{\"authorId\": \"1738219\", \"name\": \"Alejandro Bellog\\u00edn\"}, {\"authorId\": \"2912921\", \"name\": \"P. Castells\"}, {\"authorId\": \"1737406\", \"name\": \"Iv\\u00e1n Cantador\"}]}, {\"paperId\": \"6cc4531ac17956eb31fc41f51ac9bb3882d15624\", \"title\": \"The Capacity of Robust Private Information Retrieval With Colluding Databases\", \"abstract\": \"Private information retrieval (PIR) is the problem of retrieving as efficiently as possible, one out of  $K$  messages from  $N$  non-communicating replicated databases (each holds all  $K$  messages) while keeping the identity of the desired message index a secret from each individual database. The information theoretic capacity of PIR (equivalently, the reciprocal of minimum download cost) is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information.  $T$ -private PIR is a generalization of PIR to include the requirement that even if any  $T$  of the  $N$  databases collude, the identity of the retrieved message remains completely unknown to them. Robust PIR is another generalization that refers to the scenario where we have  $M \\\\geq N$  databases, out of which any  $M - N$  may fail to respond. For  $K$  messages and  $M\\\\geq N$  databases out of which at least some  $N$  must respond, we show that the capacity of  $T$ -private and Robust PIR is  $(1+T/N+T^{2}/N^{2}+\\\\cdots +T^{K-1}/N^{K-1})^{-1}$ . The result includes as special cases the capacity of PIR without robustness ( $M=N$ ) or  $T$ -privacy constraints ( $T=1$ ).\", \"venue\": \"IEEE Transactions on Information Theory\", \"year\": 2016, \"authors\": [{\"authorId\": \"143844138\", \"name\": \"Hua Sun\"}, {\"authorId\": \"145486824\", \"name\": \"S. Jafar\"}]}, {\"paperId\": \"3041a9265afb2ebdb4915aa9572668bb7f32b0ef\", \"title\": \"From Word Embeddings to Document Similarities for Improved Information Retrieval in Software Engineering\", \"abstract\": \"The application of information retrieval techniques to search tasks in software engineering is made difficult by the lexical gap between search queries, usually expressed in natural language (e.g. English), and retrieved documents, usually expressed in code (e.g. programming languages). This is often the case in bug and feature location, community question answering, or more generally the communication between technical personnel and non-technical stake holders in a software project. In this paper, we propose bridging the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space. In the proposed architecture, word embeddings are rst trained on API documents, tutorials, and reference documents, and then aggregated in order to estimate semantic similarities between documents. Empirical evaluations show that the learned vector space embeddings lead to improvements in a previously explored bug localization task and a newly de ned task of linking API documents to computer programming questions.\", \"venue\": \"International Conference on Software Engineering\", \"year\": 2016, \"authors\": [{\"authorId\": \"1836278643\", \"name\": \"Xin Ye\"}, {\"authorId\": \"2110826308\", \"name\": \"Hui Shen\"}, {\"authorId\": \"2115573502\", \"name\": \"Xiao Ma\"}, {\"authorId\": \"3139133\", \"name\": \"Razvan C. Bunescu\"}, {\"authorId\": \"2118483756\", \"name\": \"Chang Liu\"}]}, {\"paperId\": \"03995790bf86a1c34fd02c072d05a1ecfaa603cb\", \"title\": \"Information Retrieval and Text Mining Technologies for Chemistry.\", \"abstract\": \"Efficient access to chemical information contained in scientific literature, patents, technical reports, or the web is a pressing need shared by researchers and patent attorneys from different chemical disciplines. Retrieval of important chemical information in most cases starts with finding relevant documents for a particular chemical compound or family. Targeted retrieval of chemical documents is closely connected to the automatic recognition of chemical entities in the text, which commonly involves the extraction of the entire list of chemicals mentioned in a document, including any associated information. In this Review, we provide a comprehensive and in-depth description of fundamental concepts, technical implementations, and current technologies for meeting these information demands. A strong focus is placed on community challenges addressing systems performance, more particularly CHEMDNER and CHEMDNER patents tasks of BioCreative IV and V, respectively. Considering the growing interest in the construction of automatically annotated chemical knowledge bases that integrate chemical information and biological data, cheminformatics approaches for mapping the extracted chemical names into chemical structures and their subsequent annotation together with text mining applications for linking chemistry with biological information are also presented. Finally, future trends and current challenges are highlighted as a roadmap proposal for research in this emerging field.\", \"venue\": \"Chemical Reviews\", \"year\": 2017, \"authors\": [{\"authorId\": \"3286328\", \"name\": \"Martin Krallinger\"}, {\"authorId\": \"3357404\", \"name\": \"O. Rabal\"}, {\"authorId\": \"38211958\", \"name\": \"A. Louren\\u00e7o\"}, {\"authorId\": \"1889900\", \"name\": \"J. Oyarz\\u00e1bal\"}, {\"authorId\": \"145786321\", \"name\": \"A. Valencia\"}]}, {\"paperId\": \"4467c4dd82747f0e58cb5c52cb19c994c0082a89\", \"title\": \"Private information retrieval from MDS coded data in distributed storage systems\", \"abstract\": \"We consider the problem of providing privacy, in the private information retrieval (PIR) sense, to users requesting data from a distributed storage system (DSS). The DSS uses an (n, k) Maximum Distance Separable (MDS) code to store the data reliably on unreliable storage nodes. Some of these nodes can be spies which report to a third party, such as an oppressive regime, which data is being requested by the user. An information theoretic PIR scheme ensures that a user can satisfy its request while revealing, to the spy nodes, no information on which data is being requested. A user can achieve PIR by downloading all the data in the DSS. However, this is not a feasible solution due to its high communication cost. We construct PIR schemes with low download communication cost. When there is b = 1 spy node in the DSS, we construct PIR schemes with download cost 1/1-R per unit of requested data (R = k/n is the code rate), achieving the information theoretic limit for linear schemes. The proposed schemes are universal since they depend on the code rate, but not on the generator matrix of the code. When there are 2 \\u2264 b \\u2264 n - k spy nodes, we devise linear PIR schemes that have download cost equal to b + k per unit of requested data.\", \"venue\": \"International Symposium on Information Theory\", \"year\": 2016, \"authors\": [{\"authorId\": \"78653009\", \"name\": \"Razane Tajeddine\"}, {\"authorId\": \"40464010\", \"name\": \"S. Rouayheb\"}]}, {\"paperId\": \"9130ed011369ee8c4853b562309289488fb5949a\", \"title\": \"Query Expansion Techniques for Information Retrieval: a Survey\", \"abstract\": null, \"venue\": \"Information Processing & Management\", \"year\": 2017, \"authors\": [{\"authorId\": \"9408461\", \"name\": \"Dr. Hiteshwar Kumar Azad\"}, {\"authorId\": \"47214235\", \"name\": \"A. Deepak\"}]}, {\"paperId\": \"7e8d5a108c28cdfb92f419ce919fbf7993dfebfc\", \"title\": \"A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval\", \"abstract\": \"In this paper, we propose a new latent semantic model that incorporates a convolutional-pooling structure over word sequences to learn low-dimensional, semantic vector representations for search queries and Web documents. In order to capture the rich contextual structures in a query or a document, we start with each word within a temporal context window in a word sequence to directly capture contextual features at the word n-gram level. Next, the salient word n-gram features in the word sequence are discovered by the model and are then aggregated to form a sentence-level feature vector. Finally, a non-linear transformation is applied to extract high-level semantic information to generate a continuous vector representation for the full text string. The proposed convolutional latent semantic model (CLSM) is trained on clickthrough data and is evaluated on a Web document ranking task using a large-scale, real-world data set. Results show that the proposed model effectively captures salient semantic information in queries and documents for the task while significantly outperforming previous state-of-the-art semantic models.\", \"venue\": \"International Conference on Information and Knowledge Management\", \"year\": 2014, \"authors\": [{\"authorId\": \"1752875\", \"name\": \"Yelong Shen\"}, {\"authorId\": \"144137069\", \"name\": \"Xiaodong He\"}, {\"authorId\": \"1800422\", \"name\": \"Jianfeng Gao\"}, {\"authorId\": \"144718788\", \"name\": \"L. Deng\"}, {\"authorId\": \"1935910\", \"name\": \"Gr\\u00e9goire Mesnil\"}]}, {\"paperId\": \"26afce2b127e6291d87dba76391343a65b0bca8b\", \"title\": \"On the concept of relevance in legal information retrieval\", \"abstract\": null, \"venue\": \"Artificial Intelligence and Law\", \"year\": 2017, \"authors\": [{\"authorId\": \"2796718\", \"name\": \"M. V. Opijnen\"}, {\"authorId\": \"49465144\", \"name\": \"Cristiana Santos\"}]}, {\"paperId\": \"22ae02d81c21cb90b0de071550cfb99e6a623e62\", \"title\": \"Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval\", \"abstract\": \"This paper develops a model that addresses sentence embedding, a hot topic in current natural language processing research, using recurrent neural networks (RNN) with Long Short-Term Memory (LSTM) cells. The proposed LSTM-RNN model sequentially takes each word in a sentence, extracts its information, and embeds it into a semantic vector. Due to its ability to capture long term memory, the LSTM-RNN accumulates increasingly richer information as it goes through the sentence, and when it reaches the last word, the hidden layer of the network provides a semantic representation of the whole sentence. In this paper, the LSTM-RNN is trained in a weakly supervised manner on user click-through data logged by a commercial web search engine. Visualization and analysis are performed to understand how the embedding process works. The model is found to automatically attenuate the unimportant words and detect the salient keywords in the sentence. Furthermore, these detected keywords are found to automatically activate different cells of the LSTM-RNN, where words belonging to a similar topic activate the same cell. As a semantic representation of the sentence, the embedding vector can be used in many different applications. These automatic keyword detection and topic allocation abilities enabled by the LSTM-RNN allow the network to perform document retrieval, a difficult language processing task, where the similarity between the query and documents can be measured by the distance between their corresponding sentence embedding vectors computed by the LSTM-RNN. On a web search task, the LSTM-RNN embedding is shown to significantly outperform several existing state of the art methods. We emphasize that the proposed model generates sentence embedding vectors that are specially useful for web document retrieval tasks. A comparison with a well known general sentence embedding method, the Paragraph Vector, is performed. The results show that the proposed method in this paper significantly outperforms Paragraph Vector method for web document retrieval task.\", \"venue\": \"IEEE/ACM Transactions on Audio Speech and Language Processing\", \"year\": 2015, \"authors\": [{\"authorId\": \"2542427\", \"name\": \"H. Palangi\"}, {\"authorId\": \"144718788\", \"name\": \"L. Deng\"}, {\"authorId\": \"1752875\", \"name\": \"Yelong Shen\"}, {\"authorId\": \"1800422\", \"name\": \"Jianfeng Gao\"}, {\"authorId\": \"144137069\", \"name\": \"Xiaodong He\"}, {\"authorId\": \"1720246\", \"name\": \"Jianshu Chen\"}, {\"authorId\": \"2831106\", \"name\": \"Xinying Song\"}, {\"authorId\": \"39079344\", \"name\": \"R. Ward\"}]}, {\"paperId\": \"38735f5ddde4a637d3cfdc039874c120ce1d5bff\", \"title\": \"XPIR : Private Information Retrieval for Everyone\", \"abstract\": \"Abstract A Private Information Retrieval (PIR) scheme is a protocol in which a user retrieves a record from a database while hiding which from the database administrators. PIR can be achieved using mutuallydistrustful replicated databases, trusted hardware, or cryptography. In this paper we focus on the later setting which is known as single-database computationally- Private Information Retrieval (cPIR). Classic cPIR protocols require that the database server executes an algorithm over all the database content at very low speeds which impairs their usage. In [1], given certain assumptions, realistic at the time, Sion and Carbunar showed that cPIR schemes were not practical and most likely would never be. To this day, this conclusion is widely accepted by researchers and practitioners. Using the paradigm shift introduced by lattice-based cryptography, we show that the conclusion of Sion and Carbunar is not valid anymore: cPIR is of practical value. This is achieved without compromising security, using standard crytosystems, and conservative parameter choices.\", \"venue\": \"Proceedings on Privacy Enhancing Technologies\", \"year\": 2016, \"authors\": [{\"authorId\": \"1681525\", \"name\": \"C. A. Melchor\"}, {\"authorId\": \"46775133\", \"name\": \"Joris Barrier\"}, {\"authorId\": \"1735874\", \"name\": \"Laurent Fousse\"}, {\"authorId\": \"1798219\", \"name\": \"Marc-Olivier Killijian\"}]}, {\"paperId\": \"414813fb61636b74cb1136545401e71780fe0bbf\", \"title\": \"The Capacity of Symmetric Private Information Retrieval\", \"abstract\": \"Private information retrieval (PIR) is the problem of retrieving as efficiently as possible, one out of K messages from N non- communicating replicated databases (each holds all K messages) while keeping the identity of the desired message index a secret from each individual database. Symmetric PIR (SPIR) is a generalization of PIR to include the requirement that beyond the desired message, the user learns nothing about the other K − 1 messages. The information theoretic capacity of SPIR (equivalently, the reciprocal of minimum download cost) is the maximum number of bits of desired information that can be privately retrieved per bit of downloaded information. We show that the capacity of SPIR is 1−1/N regardless of the number of messages K, if the databases have access to common randomness (not available to the user) that is independent of the messages, in the amount that is at least 1/(N −1) bits per desired message bit, and zero otherwise.\", \"venue\": \"2016 IEEE Globecom Workshops (GC Wkshps)\", \"year\": 2016, \"authors\": [{\"authorId\": \"143844138\", \"name\": \"Hua Sun\"}, {\"authorId\": \"145486824\", \"name\": \"S. Jafar\"}]}, {\"paperId\": \"44e915a220ce74badf755aae870fa0b69ee2b82a\", \"title\": \"Naive (Bayes) at Forty: The Independence Assumption in Information Retrieval\", \"abstract\": null, \"venue\": \"European Conference on Machine Learning\", \"year\": 1998, \"authors\": [{\"authorId\": \"35153517\", \"name\": \"D. Lewis\"}]}, {\"paperId\": \"66aff3976b8aeaaca141bf1cbbff7e59bfaedcac\", \"title\": \"A Survey of Query Auto Completion in Information Retrieval\", \"abstract\": \"In information retrieval, query auto completion (QAC), also known as type-ahead and auto-complete suggestion, refers to the following functionality: given a prex consisting of a number of characters entered into a search box, the user interface proposes alternative ways of extending the prex to a full query. QAC helps users to formulate their query when they have an intent in mind but not a clear way of expressing this in a query. It helps to avoid possible spelling mistakes, especially on devices with small screens. It saves keystrokes and cuts down the search duration of users which implies a lower load on the search engine, and results in savings in machine resources and maintenance. Because of the clear benets of QAC, a considerable number of algorithmic approaches to QAC have been proposed in the past few years. Query logs have proven to be a key asset underlying most of the recent research. This monograph surveys this research. It focuses on summarizing the literature on QAC and provides a general understanding of the wealth of QAC approaches that are currently available. A Survey of Query Auto Completion in Information Retrieval is an ideal reference on the topic. Its contributions can be summarized as follows: It provides researchers who are working on query auto completion or related problems in the eld of information retrieval with a good overview and analysis of state-of-the-art QAC approaches. In particular, for researchers new to the eld, the survey can serve as an introduction to the state-of-the-art. It also offers a comprehensive perspective on QAC approaches by presenting a taxonomy of existing solutions. In addition, it presents solutions for QAC under different conditions such as available high-resolution query logs, in-depth user interactions with QAC using eye-tracking, and elaborate user engagements in a QAC process. It also discusses practical issues related to QAC. Lastly, it presents a detailed discussion of core challenges and promising open directions in QAC.\", \"venue\": \"Foundations and Trends in Information Retrieval\", \"year\": 2016, \"authors\": [{\"authorId\": \"145030663\", \"name\": \"Fei Cai\"}, {\"authorId\": \"1696030\", \"name\": \"M. de Rijke\"}]}, {\"paperId\": \"9ca8c15b5d348d84efd881bec0d2caa7aa190302\", \"title\": \"Information Retrieval Implementing And Evaluating Search Engines\", \"abstract\": \"Thank you for downloading information retrieval implementing and evaluating search engines. Maybe you have knowledge that, people have look hundreds times for their chosen novels like this information retrieval implementing and evaluating search engines, but end up in harmful downloads. Rather than enjoying a good book with a cup of coffee in the afternoon, instead they cope with some malicious virus inside their desktop computer.\", \"venue\": \"\", \"year\": 2016, \"authors\": [{\"authorId\": \"48383036\", \"name\": \"N. Bauer\"}]}, {\"paperId\": \"9bf9d3a0c2e6ffb41b145d7f277f7a0d750eb478\", \"title\": \"Online Evaluation for Information Retrieval\", \"abstract\": \"Online evaluation is one of the most common approaches to measure the effectiveness of an information retrieval system. It involves fielding the information retrieval system to real users, and observing these users' interactions in-situ while they engage with the system. This allows actual users with real world information needs to play an important part in assessing retrieval quality. As such, online evaluation complements the common alternative offline evaluation approaches which may provide more easily interpretable outcomes, yet are often less realistic when measuring of quality and actual user experience.In this survey, we provide an overview of online evaluation techniques for information retrieval. We show how online evaluation is used for controlled experiments, segmenting them into experiment designs that allow absolute or relative quality assessments. Our presentation of different metrics further partitions online evaluation based on different sized experimental units commonly of interest: documents, lists and sessions. Additionally, we include an extensive discussion of recent work on data re-use, and experiment estimation based on historical data.A substantial part of this work focuses on practical issues: How to run evaluations in practice, how to select experimental parameters, how to take into account ethical considerations inherent in online evaluations, and limitations that experimenters should be aware of. While most published work on online experimentation today is at large scale in systems with millions of users, we also emphasize that the same techniques can be applied at small scale. To this end, we emphasize recent work that makes it easier to use at smaller scales and encourage studying real-world information seeking in a wide range of scenarios. Finally, we present a summary of the most recent work in the area, and describe open problems, as well as postulating future directions.\", \"venue\": \"Foundations and Trends in Information Retrieval\", \"year\": 2016, \"authors\": [{\"authorId\": \"145186674\", \"name\": \"Katja Hofmann\"}, {\"authorId\": \"47681372\", \"name\": \"Lihong Li\"}, {\"authorId\": \"1803571\", \"name\": \"Filip Radlinski\"}]}, {\"paperId\": \"109398d45e12a0e8bfdf0010ab3036251da9d100\", \"title\": \"Multiround Private Information Retrieval: Capacity and Storage Overhead\", \"abstract\": \"Private information retrieval (PIR) is the problem of retrieving one message out of  $K$  messages from  $N$  non-communicating replicated databases, where each database stores all  $K$  messages, in such a way that each database learns no information about which message is being retrieved. The capacity of PIR is the maximum number of bits of desired information per bit of downloaded information among all PIR schemes. The capacity has recently been characterized for PIR as well as several of its variants. In every case it is assumed that all the queries are generated by the user simultaneously. Here we consider multiround PIR, where the queries in each round are allowed to depend on the answers received in previous rounds. We show that the capacity of multiround PIR is the same as the capacity of single-round PIR. The result is generalized to also include  $T$ -privacy constraints. Combined with previous results, this shows that there is no capacity advantage from multiround over single-round schemes, non-linear over linear schemes or from  $\\\\epsilon $ -error over zero-error schemes. However, we show through an example that there is an advantage in terms of storage overhead. We provide an example of a multiround, non-linear,  $\\\\epsilon $ -error PIR scheme that requires a strictly smaller storage overhead than the best possible with single-round, linear, zero-error PIR schemes.\", \"venue\": \"IEEE Transactions on Information Theory\", \"year\": 2016, \"authors\": [{\"authorId\": \"143844138\", \"name\": \"Hua Sun\"}, {\"authorId\": \"145486824\", \"name\": \"S. Jafar\"}]}, {\"paperId\": \"b4c04125ea2ff8ad7010b900bd1481b9c18da98b\", \"title\": \"A generic framework for ontology-based information retrieval and image retrieval in web data\", \"abstract\": null, \"venue\": \"Human-Centric Computing and Information Sciences\", \"year\": 2016, \"authors\": [{\"authorId\": \"7255006\", \"name\": \"V. Vijayarajan\"}, {\"authorId\": \"144119884\", \"name\": \"M. Dinakaran\"}, {\"authorId\": \"3376877\", \"name\": \"Priyam Tejaswin\"}, {\"authorId\": \"8522416\", \"name\": \"Mayank Lohani\"}]}, {\"paperId\": \"6050944a981fe98f921ed779e59a9e44e045ce3d\", \"title\": \"Monolingual and Cross-Lingual Information Retrieval Models Based on (Bilingual) Word Embeddings\", \"abstract\": \"We propose a new unified framework for monolingual (MoIR) and cross-lingual information retrieval (CLIR) which relies on the induction of dense real-valued word vectors known as word embeddings (WE) from comparable data. To this end, we make several important contributions: (1) We present a novel word representation learning model called Bilingual Word Embeddings Skip-Gram (BWESG) which is the first model able to learn bilingual word embeddings solely on the basis of document-aligned comparable data; (2) We demonstrate a simple yet effective approach to building document embeddings from single word embeddings by utilizing models from compositional distributional semantics. BWESG induces a shared cross-lingual embedding vector space in which both words, queries, and documents may be presented as dense real-valued vectors; (3) We build novel ad-hoc MoIR and CLIR models which rely on the induced word and document embeddings and the shared cross-lingual embedding space; (4) Experiments for English and Dutch MoIR, as well as for English-to-Dutch and Dutch-to-English CLIR using benchmarking CLEF 2001-2003 collections and queries demonstrate the utility of our WE-based MoIR and CLIR models. The best results on the CLEF collections are obtained by the combination of the WE-based approach and a unigram language model. We also report on significant improvements in ad-hoc IR tasks of our WE-based framework over the state-of-the-art framework for learning text representations from comparable data based on latent Dirichlet allocation (LDA).\", \"venue\": \"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\", \"year\": 2015, \"authors\": [{\"authorId\": \"1747849\", \"name\": \"Ivan Vulic\"}, {\"authorId\": \"145446752\", \"name\": \"Marie-Francine Moens\"}]}, {\"paperId\": \"49c6cc0b9f25fa6f35f336108e1f03f4de7a2917\", \"title\": \"Information retrieval as semantic inference: a Graph Inference model applied to medical search\", \"abstract\": null, \"venue\": \"Information Retrieval Journal\", \"year\": 2016, \"authors\": [{\"authorId\": \"1783566\", \"name\": \"B. Koopman\"}, {\"authorId\": \"1692855\", \"name\": \"G. Zuccon\"}, {\"authorId\": \"1755431\", \"name\": \"P. Bruza\"}, {\"authorId\": \"1780364\", \"name\": \"Laurianne Sitbon\"}, {\"authorId\": \"1702058\", \"name\": \"Michael Lawley\"}]}, {\"paperId\": \"d66a826ad8f66419292cf5a5c7ed22f114681b40\", \"title\": \"APPLYING GENETIC ALGORITHMS TO INFORMATION RETRIEVAL USING VECTOR SPACE MODEL\", \"abstract\": \"Genetic algorithms are usually used in information retrieval systems (IRs) to enhance the information retrieval process, and to increase the efficiency of the optimal information retrieval in order to meet the users' needs and help them find what they want exactly among the growing numbers of available information. The improvement of adaptive genetic algorithms helps to retrieve the information needed by the user accurately, reduces the retrieved relevant files and excludes irrelevant files. In this study, the researcher explored the problems embedded in this process, attempted to find solutions such as the way of choosing mutation probability and fitness function, and chose Cranfield English Corpus test collection on mathematics. Such collection was conducted by Cyrial Cleverdon and used at the University of Cranfield in 1960 containing 1400 documents, and 225 queries for simulation purposes. The researcher also used cosine similarity and jaccards to compute similarity between the query and documents, and used two proposed adaptive fitness function, mutation operators as well as adaptive crossover. The process aimed at evaluating the effectiveness of results according to the measures of precision and recall. Finally, the study concluded that we might have several improvements when using adaptive genetic algorithms. \\ufffd\", \"venue\": \"\", \"year\": 2015, \"authors\": [{\"authorId\": \"7833679\", \"name\": \"L. Abualigah\"}, {\"authorId\": \"25133390\", \"name\": \"Essam Said Hanandeh\"}]}, {\"paperId\": \"42cf161894f4b9ebb86a9109dc2af45d9eee8916\", \"title\": \"Integrating and Evaluating Neural Word Embeddings in Information Retrieval\", \"abstract\": \"Recent advances in neural language models have contributed new methods for learning distributed vector representations of words (also called word embeddings). Two such methods are the continuous bag-of-words model and the skipgram model. These methods have been shown to produce embeddings that capture higher order relationships between words that are highly effective in natural language processing tasks involving the use of word similarity and word analogy. Despite these promising results, there has been little analysis of the use of these word embeddings for retrieval. Motivated by these observations, in this paper, we set out to determine how these word embeddings can be used within a retrieval model and what the benefit might be. To this aim, we use neural word embeddings within the well known translation language model for information retrieval. This language model captures implicit semantic relations between the words in queries and those in relevant documents, thus producing more accurate estimations of document relevance. The word embeddings used to estimate neural language models produce translations that differ from previous translation language model approaches; differences that deliver improvements in retrieval effectiveness. The models are robust to choices made in building word embeddings and, even more so, our results show that embeddings do not even need to be produced from the same corpus being used for retrieval.\", \"venue\": \"Australasian Document Computing Symposium\", \"year\": 2015, \"authors\": [{\"authorId\": \"1692855\", \"name\": \"G. Zuccon\"}, {\"authorId\": \"1783566\", \"name\": \"B. Koopman\"}, {\"authorId\": \"1755431\", \"name\": \"P. Bruza\"}, {\"authorId\": \"1716332\", \"name\": \"L. Azzopardi\"}]}, {\"paperId\": \"9695b92f08d563ec053d4c89927836d9c8f01d26\", \"title\": \"Information retrieval for music and motion\", \"abstract\": null, \"venue\": \"\", \"year\": 2007, \"authors\": [{\"authorId\": \"2116144530\", \"name\": \"Meinard M\\u00fcller\"}]}, {\"paperId\": \"d8a358fb026fda39546cf8e3cbf9e5d754d63463\", \"title\": \"An Information Retrieval Approach to Short Text Conversation\", \"abstract\": \"Human computer conversation is regarded as one of the most difficult problems in artificial intelligence. In this paper, we address one of its key sub-problems, referred to as short text conversation, in which given a message from human, the computer returns a reasonable response to the message. We leverage the vast amount of short conversation data available on social media to study the issue. We propose formalizing short text conversation as a search problem at the first step, and employing state-of-the-art information retrieval (IR) techniques to carry out the task. We investigate the significance as well as the limitation of the IR approach. Our experiments demonstrate that the retrieval-based model can make the system behave rather \\\"intelligently\\\", when combined with a huge repository of conversation data from social media.\", \"venue\": \"ArXiv\", \"year\": 2014, \"authors\": [{\"authorId\": \"1701747\", \"name\": \"Zongcheng Ji\"}, {\"authorId\": \"11955007\", \"name\": \"Zhengdong Lu\"}, {\"authorId\": \"49404233\", \"name\": \"Hang Li\"}]}, {\"paperId\": \"3957ed745aeb22383639beca708b52f69d58697f\", \"title\": \"A Privacy-Preserving Framework for Large-Scale Content-Based Information Retrieval\", \"abstract\": \"We propose a privacy protection framework for large-scale content-based information retrieval. It offers two layers of protection. First, robust hash values are used as queries to prevent revealing original content or features. Second, the client can choose to omit certain bits in a hash value to further increase the ambiguity for the server. Due to the reduced information, it is computationally difficult for the server to know the client's interest. The server has to return the hash values of all possible candidates to the client. The client performs a search within the candidate list to find the best match. Since only hash values are exchanged between the client and the server, the privacy of both parties is protected. We introduce the concept oftunable privacy, where the privacy protection level can be adjusted according to a policy. It is realized through hash-based piecewise inverted indexing. The idea is to divide a feature vector into pieces and index each piece with a subhash value. Each subhash value is associated with an inverted index list. The framework has been extensively tested using a large image database. We have evaluated both retrieval performance and privacy-preserving performance for a particular content identification application. Two different constructions of robust hash algorithms are used. One is based on random projections; the other is based on the discrete wavelet transform. Both algorithms exhibit satisfactory performance in comparison with state-of-the-art retrieval schemes. The results show that the privacy enhancement slightly improves the retrieval performance. We consider the majority voting attack for estimating the query category and identification. Experiment results show that this attack is a threat when there are near-duplicates, but the success rate decreases with the number of omitted bits and the number of distinct items.\", \"venue\": \"IEEE Transactions on Information Forensics and Security\", \"year\": 2015, \"authors\": [{\"authorId\": \"145826548\", \"name\": \"Li Weng\"}, {\"authorId\": \"1778357\", \"name\": \"L. Amsaleg\"}, {\"authorId\": \"2052641393\", \"name\": \"April Morton\"}, {\"authorId\": \"1398659765\", \"name\": \"S. Marchand-Maillet\"}]}, {\"paperId\": \"d51e5171bbb03ae4b984e6c7704b93c385618484\", \"title\": \"Music Information Retrieval: Recent Developments and Applications\", \"abstract\": \"We provide a survey of the field of Music Information Retrieval (MIR), in particular paying attention to latest developments, such as semantic auto-tagging and user-centric retrieval and recommendation approaches. We first elaborate on well-established and proven methods for feature extraction and music indexing, from both the audio signal and contextual data sources about music items, such as web pages or collaborative tags. These in turn enable a wide variety of music retrieval tasks, such as semantic music search or music identification (\\\"query by example\\\"). Subsequently, we review current work on user analysis and modeling in the context of music recommendation and retrieval, addressing the recent trend towards user-centric and adaptive approaches and systems. A discussion follows about the important aspect of how various MIR approaches to different problems are evaluated and compared. Eventually, a discussion about the major open challenges concludes the survey.\", \"venue\": \"Foundations and Trends in Information Retrieval\", \"year\": 2014, \"authors\": [{\"authorId\": \"144125621\", \"name\": \"M. Schedl\"}, {\"authorId\": \"145217215\", \"name\": \"E. G\\u00f3mez\"}, {\"authorId\": \"144554719\", \"name\": \"Juli\\u00e1n Urbano\"}]}, {\"paperId\": \"e829ee7fe48f4b1e451378b6a21470b2f86c0aa6\", \"title\": \"One extra bit of download ensures perfectly private information retrieval\", \"abstract\": \"Private information retrieval (PIR) systems allow a user to retrieve a record from a public database without revealing to the server which record is being retrieved. The literature on PIR considers only replication-based systems, wherein each storage node stores a copy of the entire data. However, systems based on erasure codes are gaining increasing popularity due to a variety of reasons. This paper initiates an investigation into PIR in erasure-coded systems by establishing its capacity and designing explicit codes and algorithms. The notion of privacy considered here is information-theoretic, and the metric optimized is the amount of data downloaded by the user during PIR. In this paper, we present four main results. First, we design an explicit erasure code and PIR algorithm that requires only one extra bit of download to provide perfect privacy. In contrast, all existing PIR algorithms require a download of at least twice the size of the requisite data. Second, we derive lower bounds proving the necessity of downloading at least one additional bit. This establishes the precise capacity of PIR with respect to the metric of download. These results are also applicable to PIR in replication-based systems, which are a special case of erasure codes. Our third contribution is a negative result showing that capacity-achieving codes necessitate super-linear storage overheads. This motivates the fourth contribution of this paper: an erasure code and PIR algorithm that requires a linear storage overhead, provides high reliability to the data, and is a small factor away from the capacity.\", \"venue\": \"2014 IEEE International Symposium on Information Theory\", \"year\": 2014, \"authors\": [{\"authorId\": \"1737249\", \"name\": \"Nihar B. Shah\"}, {\"authorId\": \"2453556\", \"name\": \"K. V. Rashmi\"}, {\"authorId\": \"144161012\", \"name\": \"K. Ramchandran\"}]}, {\"paperId\": \"1e3ded57c5d1e90e95f4f6bdbbe1cbf30ff6690f\", \"title\": \"Private information retrieval for coded storage\", \"abstract\": \"Private information retrieval scheme for coded data storage is considered in this paper. We focus on the case where the size of each data record is large and hence only the download cost (but not the upload cost for transmitting retrieval queries) is of interest. We prove that the tradeoff between storage cost and retrieval/download cost depends on the number of data records in the system. We propose a class of linear storage codes and retrieval schemes, and derive conditions under which our schemes are error-free and private. Tradeoffs between the storage cost and retrieval costs are also obtained.\", \"venue\": \"International Symposium on Information Theory\", \"year\": 2014, \"authors\": [{\"authorId\": \"144718712\", \"name\": \"T. Chan\"}, {\"authorId\": \"40630532\", \"name\": \"Siu-Wai Ho\"}, {\"authorId\": \"144959567\", \"name\": \"Hirosuke Yamamoto\"}]}, {\"paperId\": \"c88c631f204f49eff0d0a3426908463f881644fd\", \"title\": \"Survey of Temporal Information Retrieval and Related Applications\", \"abstract\": \"Temporal information retrieval has been a topic of great interest in recent years. Its purpose is to improve the effectiveness of information retrieval methods by exploiting temporal information in documents and queries. In this article, we present a survey of the existing literature on temporal information retrieval. In addition to giving an overview of the field, we categorize the relevant research, describe the main contributions, and compare different approaches. We organize existing research to provide a coherent view, discuss several open issues, and point out some possible future research directions in this area. Despite significant advances, the area lacks a systematic arrangement of prior efforts and an overview of state-of-the-art approaches. Moreover, an effective end-to-end temporal retrieval system that exploits temporal information to improve the quality of the presented results remains undeveloped.\", \"venue\": \"ACM Computing Surveys\", \"year\": 2014, \"authors\": [{\"authorId\": \"145523707\", \"name\": \"Ricardo Campos\"}, {\"authorId\": \"143673279\", \"name\": \"G. Dias\"}, {\"authorId\": \"1772839\", \"name\": \"A. Jorge\"}, {\"authorId\": \"1774986\", \"name\": \"A. Jatowt\"}]}, {\"paperId\": \"7ab00f35940fd0bcfaf5fff7c91c6b7fab9d103b\", \"title\": \"Information Retrieval with Verbose Queries\", \"abstract\": \"Recently, the focus of many novel search applications shifted from short keyword queries to verbose natural language queries. Examples include question answering systems and dialogue systems, voice search on mobile devices and entity search engines like Facebook's Graph Search or Google's Knowledge Graph. However the performance of textbook information retrieval techniques for such verbose queries is not as good as that for their shorter counterparts. Thus, effective handling of verbose queries has become a critical factor for adoption of information retrieval techniques in this new breed of search applications. Over the past decade, the information retrieval community has deeply explored the problem of transforming natural language verbose queries using operations like reduction, weighting, expansion, reformulation and segmentation into more effective structural representations. However, thus far, there was not a coherent and organized tutorial on this topic. In this tutorial, we aim to put together various research pieces of the puzzle, provide a comprehensive and structured overview of various proposed methods, and also list various application scenarios where effective verbose query processing can make a significant difference.\", \"venue\": \"Foundations and Trends in Information Retrieval\", \"year\": 2015, \"authors\": [{\"authorId\": \"46722320\", \"name\": \"Manish Gupta\"}, {\"authorId\": \"1815447\", \"name\": \"Michael Bendersky\"}]}, {\"paperId\": \"6cb234e38f7104fcd73bff04f41bfb37c96e2317\", \"title\": \"Introduction to Information Retrieval and Quantum Mechanics\", \"abstract\": null, \"venue\": \"The Information Retrieval Series\", \"year\": 2015, \"authors\": [{\"authorId\": \"1678917\", \"name\": \"M. Melucci\"}]}, {\"paperId\": \"3ff2e39dc79c34a17c4ed491e3daf3e03ee5c05d\", \"title\": \"A Survey of Automatic Query Expansion in Information Retrieval\", \"abstract\": \"The relative ineffectiveness of information retrieval systems is largely caused by the inaccuracy with which a query formed by a few keywords models the actual user information need. One well known method to overcome this limitation is automatic query expansion (AQE), whereby the user\\u2019s original query is augmented by new features with a similar meaning. AQE has a long history in the information retrieval community but it is only in the last years that it has reached a level of scientific and experimental maturity, especially in laboratory settings such as TREC. This survey presents a unified view of a large number of recent approaches to AQE that leverage various data sources and employ very different principles and techniques. The following questions are addressed. Why is query expansion so important to improve search effectiveness? What are the main steps involved in the design and implementation of an AQE component? What approaches to AQE are available and how do they compare? Which issues must still be resolved before AQE becomes a standard component of large operational information retrieval systems (e.g., search engines)?\", \"venue\": \"CSUR\", \"year\": 2012, \"authors\": [{\"authorId\": \"1701045\", \"name\": \"Claudio Carpineto\"}, {\"authorId\": \"144857383\", \"name\": \"Giovanni Romano\"}]}, {\"paperId\": \"d337c141734b24395764b897d574eb74482a47d2\", \"title\": \"Dynamic Information Retrieval Modeling\", \"abstract\": \"In Dynamic Information Retrieval modeling we model dynamic systems which change or adapt over time or a sequence of events using a range of techniques from artificial intelligence and reinforcement learning. Many of the open problems in current IR research can be described as dynamic systems, for instance, session search or computational advertising. State of the art research provides solutions to these problems that are responsive to a changing environment, learn from past interactions and predict future utility. Advances in IR interface, personalization and ad display demand models that can react to users in real time and in an intelligent, contextual way. The objective of this half-day tutorial is to provide a comprehensive and up-to-date introduction to Dynamic Information Retrieval Modeling. We motivate a conceptual model linking static, interactive and dynamic retrieval and use this to define dynamics within the context of IR. We then cover a number of algorithms and techniques from the artificial intelligence (AI) and online learning literature such as Markov Decision Processes (MDP), their partially observable variation (POMDP) and multi-armed bandits. Following this we describe how to identify dynamics in an IR problem and demonstrate how to model them using the described techniques. The remainder of the tutorial will then cover an array of state-of-the-art research on dynamic systems in IR and how they can be modeled using using dynamic IR. We use research on session search, multi-page search and online advertising as in-depth examples of such work. This tutorial is of relevance to IR practitioners and researchers, where we will present the merits of dynamic information retrieval modeling and introduce the relevant techniques. The content will be of particular interest to researchers working in the areas of statistical modeling, personalization and recommendation, and is also relevant to practitioners in Web search, online advertising and anyone who works with big data. After this tutorial, attendees will: Be able to identify the dynamics in an IR system; Be able to model these dynamics using techniques from AI and reinforcement learning; Have knowledge of the state-of-the-art research in dynamic information retrieval modeling.\", \"venue\": \"Synthesis Lectures on Information Concepts Retrieval and Services\", \"year\": 2015, \"authors\": [{\"authorId\": \"10237116\", \"name\": \"G. Yang\"}, {\"authorId\": \"37330821\", \"name\": \"Marc Sloan\"}, {\"authorId\": \"39055225\", \"name\": \"Jun Wang\"}]}, {\"paperId\": \"cabe73e89b6389a163393ecbf1b82d20ba4ea10f\", \"title\": \"Content-based multimedia information retrieval: State of the art and challenges\", \"abstract\": \"Extending beyond the boundaries of science, art, and culture, content-based multimedia information retrieval provides new paradigms and methods for searching through the myriad variety of media all over the world. This survey reviews 100+ recent articles on content-based multimedia information retrieval and discusses their role in current research directions which include browsing and search paradigms, user studies, affective computing, learning, semantic queries, new features and media types, high performance indexing, and evaluation techniques. Based on the current state of the art, we discuss the major challenges for the future.\", \"venue\": \"TOMCCAP\", \"year\": 2006, \"authors\": [{\"authorId\": \"1731570\", \"name\": \"M. Lew\"}, {\"authorId\": \"1703601\", \"name\": \"N. Sebe\"}, {\"authorId\": \"1705776\", \"name\": \"C. Djeraba\"}, {\"authorId\": \"144938740\", \"name\": \"R. Jain\"}]}, {\"paperId\": \"1604de41ea8bc82aac0502daa309d3fed3f8495e\", \"title\": \"Improving bug localization using structured information retrieval\", \"abstract\": \"Locating bugs is important, difficult, and expensive, particularly for large-scale systems. To address this, natural language information retrieval techniques are increasingly being used to suggest potential faulty source files given bug reports. While these techniques are very scalable, in practice their effectiveness remains low in accurately localizing bugs to a small number of files. Our key insight is that structured information retrieval based on code constructs, such as class and method names, enables more accurate bug localization. We present BLUiR, which embodies this insight, requires only the source code and bug reports, and takes advantage of bug similarity data if available. We build BLUiR on a proven, open source IR toolkit that anyone can use. Our work provides a thorough grounding of IR-based bug localization research in fundamental IR theoretical and empirical knowledge and practice. We evaluate BLUiR on four open source projects with approximately 3,400 bugs. Results show that BLUiR matches or outperforms a current state-of-the-art tool across applications considered, even when BLUiR does not use bug similarity data used by the other tool.\", \"venue\": \"International Conference on Automated Software Engineering\", \"year\": 2013, \"authors\": [{\"authorId\": \"2671585\", \"name\": \"Ripon K. Saha\"}, {\"authorId\": \"1747771\", \"name\": \"Matthew Lease\"}, {\"authorId\": \"145802044\", \"name\": \"S. Khurshid\"}, {\"authorId\": \"143977783\", \"name\": \"D. Perry\"}]}, {\"paperId\": \"2259fe25b38783db2769e3e2f0000689e52d70ac\", \"title\": \"Essentia: An Audio Analysis Library for Music Information Retrieval\", \"abstract\": \"Comunicacio presentada a la 14th International Society for Music Information Retrieval Conference, celebrada a Curitiba (Brasil) els dies 4 a 8 de novembre de 2013.\", \"venue\": \"International Society for Music Information Retrieval Conference\", \"year\": 2013, \"authors\": [{\"authorId\": \"144705733\", \"name\": \"D. Bogdanov\"}, {\"authorId\": \"1793520\", \"name\": \"N. Wack\"}, {\"authorId\": \"145217215\", \"name\": \"E. G\\u00f3mez\"}, {\"authorId\": \"2489825\", \"name\": \"Sankalp Gulati\"}, {\"authorId\": \"144906288\", \"name\": \"P. Herrera\"}, {\"authorId\": \"2973411\", \"name\": \"Oscar Mayor\"}, {\"authorId\": \"35581798\", \"name\": \"Gerard Roma\"}, {\"authorId\": \"1786276\", \"name\": \"J. Salamon\"}, {\"authorId\": \"1882841\", \"name\": \"J. R. Zapata\"}, {\"authorId\": \"144611740\", \"name\": \"X. Serra\"}]}, {\"paperId\": \"6871f6c5437a747fae75a19962f418d234ce2dc1\", \"title\": \"Multi-modal Transformer for Video Retrieval\", \"abstract\": null, \"venue\": \"European Conference on Computer Vision\", \"year\": 2020, \"authors\": [{\"authorId\": \"151352107\", \"name\": \"Valentin Gabeur\"}, {\"authorId\": \"1491624845\", \"name\": \"Chen Sun\"}, {\"authorId\": \"72492981\", \"name\": \"Alahari Karteek\"}, {\"authorId\": \"2462253\", \"name\": \"C. Schmid\"}]}, {\"paperId\": \"047dcb24c6e314087794842a8c1ba3ee4490893a\", \"title\": \"Balancing exploration and exploitation in listwise and pairwise online learning to rank for information retrieval\", \"abstract\": null, \"venue\": \"Information retrieval (Boston)\", \"year\": 2013, \"authors\": [{\"authorId\": \"145186674\", \"name\": \"Katja Hofmann\"}, {\"authorId\": \"1766767\", \"name\": \"Shimon Whiteson\"}, {\"authorId\": \"1696030\", \"name\": \"M. de Rijke\"}]}, {\"paperId\": \"9f4ec57919f892dc1e4b56637b3ef1f34c1b0316\", \"title\": \"Freenet: A Distributed Anonymous Information Storage and Retrieval System\", \"abstract\": null, \"venue\": \"Workshop on Design Issues in Anonymity and Unobservability\", \"year\": 2000, \"authors\": [{\"authorId\": \"121826540\", \"name\": \"I. Clarke\"}, {\"authorId\": \"145127006\", \"name\": \"Oskar Sandberg\"}, {\"authorId\": \"145419473\", \"name\": \"Brandon Wiley\"}, {\"authorId\": \"145661808\", \"name\": \"Theodore W. Hong\"}]}, {\"paperId\": \"e1a8434b864cfd162daac37fc6b9255a2a40e0f2\", \"title\": \"An Introduction to Information Retrieval\", \"abstract\": null, \"venue\": \"\", \"year\": 2013, \"authors\": [{\"authorId\": \"144161686\", \"name\": \"S. Ceri\"}, {\"authorId\": \"1710630\", \"name\": \"A. Bozzon\"}, {\"authorId\": \"40350773\", \"name\": \"Marco Brambilla\"}, {\"authorId\": \"2539248\", \"name\": \"Emanuele Della Valle\"}, {\"authorId\": \"1704595\", \"name\": \"P. Fraternali\"}, {\"authorId\": \"1794305\", \"name\": \"S. Quarteroni\"}]}, {\"paperId\": \"06871028d4e71ceefe879853e9dc2183ea81bb32\", \"title\": \"Using Linear Algebra for Intelligent Information Retrieval\", \"abstract\": \"Currently, most approaches to retrieving textual materials from scientific databases depend on a lexical match between words in users\\u2019 requests and those in or assigned to documents in a database. ...\", \"venue\": \"SIAM Review\", \"year\": 1995, \"authors\": [{\"authorId\": \"2271549\", \"name\": \"M. Berry\"}, {\"authorId\": \"1728602\", \"name\": \"S. Dumais\"}, {\"authorId\": \"1401512392\", \"name\": \"G. O'Brien\"}]}, {\"paperId\": \"16a66a1b7734f869e671197ca1ebcef1298fe5b0\", \"title\": \"The neglected user in music information retrieval research\", \"abstract\": null, \"venue\": \"Journal of Intelligence and Information Systems\", \"year\": 2013, \"authors\": [{\"authorId\": \"144125621\", \"name\": \"M. Schedl\"}, {\"authorId\": \"1718282\", \"name\": \"A. Flexer\"}, {\"authorId\": \"144554719\", \"name\": \"Juli\\u00e1n Urbano\"}]}, {\"paperId\": \"089d8cfc97d0e00c3d46dd4796e6261a0140f0c3\", \"title\": \"APTEEN: a hybrid protocol for efficient routing and comprehensive information retrieval in wireless\", \"abstract\": \"Wireless sensor networks with thousands of tiny sensor nodes, are expected to find wide applicability and increasing deployment in coming years, as they enable reliable monitoring and analysis of the environment. In this paper, we propose a hybrid routing protocol (APTEEN) which allows for comprehensive information retrieval. The nodes in such a network not only react to time-critical situations, but also give an overall picture of the network at periodic intervals in a very energy efficient manner. Such a network enables the user to request past, present and future data from the network in the form of historical, one-time and persistent queries respectively. We evaluated the performance of these protocols and observe that these protocols are observed to outperform existing protocols in terms of energy consumption and longevity of the network.\", \"venue\": \"Proceedings 16th International Parallel and Distributed Processing Symposium\", \"year\": 2002, \"authors\": [{\"authorId\": \"2480353\", \"name\": \"A. Manjeshwar\"}, {\"authorId\": \"2059077698\", \"name\": \"D. Agrawal\"}]}, {\"paperId\": \"bbadc66b0c919bf0aa4e26c7ecae86b495391057\", \"title\": \"Personalised Information Retrieval: survey and classification\", \"abstract\": null, \"venue\": \"User modeling and user-adapted interaction\", \"year\": 2013, \"authors\": [{\"authorId\": \"1767499\", \"name\": \"M. R. Ghorab\"}, {\"authorId\": \"144066008\", \"name\": \"Dong Zhou\"}, {\"authorId\": \"1397619317\", \"name\": \"A. O'Connor\"}, {\"authorId\": \"1715807\", \"name\": \"V. Wade\"}]}, {\"paperId\": \"e7846369553a81bea6b191d7b4c2fd9ed7a223eb\", \"title\": \"Evaluation in Music Information Retrieval\", \"abstract\": null, \"venue\": \"Journal of Intelligence and Information Systems\", \"year\": 2013, \"authors\": [{\"authorId\": \"144554719\", \"name\": \"Juli\\u00e1n Urbano\"}, {\"authorId\": \"144125621\", \"name\": \"M. Schedl\"}, {\"authorId\": \"144611740\", \"name\": \"X. Serra\"}]}, {\"paperId\": \"629a62c681a03ab7875d0883a986978b280e76d3\", \"title\": \"Outsourced symmetric private information retrieval\", \"abstract\": \"In the setting of searchable symmetric encryption (SSE), a data owner D outsources a database (or document/file collection) to a remote server E in encrypted form such that D can later search the collection at E while hiding information about the database and queries from E. Leakage to E is to be confined to well-defined forms of data-access and query patterns while preventing disclosure of explicit data and query plaintext values. Recently, Cash et al. presented a protocol, OXT, which can run arbitrary boolean queries in the SSE setting and which is remarkably efficient even for very large databases. In this paper we investigate a richer setting in which the data owner D outsources its data to a server E but D is now interested to allow clients (third parties) to search the database such that clients learn the information D authorizes them to learn but nothing else while E still does not learn about the data or queried values as in the basic SSE setting. Furthermore, motivated by a wide range of applications, we extend this model and requirements to a setting where, similarly to private information retrieval, the client's queried values need to be hidden also from the data owner D even though the latter still needs to authorize the query. Finally, we consider the scenario in which authorization can be enforced by the data owner D without D learning the policy, a setting that arises in court-issued search warrants. We extend the OXT protocol of Cash et al. to support arbitrary boolean queries in all of the above models while withstanding adversarial non-colluding servers (D and E) and arbitrarily malicious clients, and while preserving the remarkable performance of the protocol.\", \"venue\": \"IACR Cryptology ePrint Archive\", \"year\": 2013, \"authors\": [{\"authorId\": \"1720978\", \"name\": \"Stanislaw Jarecki\"}, {\"authorId\": \"2878366\", \"name\": \"C. Jutla\"}, {\"authorId\": \"4451238\", \"name\": \"H. Krawczyk\"}, {\"authorId\": \"144191430\", \"name\": \"Marcel-Catalin Rosu\"}, {\"authorId\": \"1443777331\", \"name\": \"M. Steiner\"}]}, {\"paperId\": \"a81874b4a651a740fffbfc47ef96515e8c7f782f\", \"title\": \"Latent Retrieval for Weakly Supervised Open Domain Question Answering\", \"abstract\": \"Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.\", \"venue\": \"Annual Meeting of the Association for Computational Linguistics\", \"year\": 2019, \"authors\": [{\"authorId\": \"2544107\", \"name\": \"Kenton Lee\"}, {\"authorId\": \"1744179\", \"name\": \"Ming-Wei Chang\"}, {\"authorId\": \"3259253\", \"name\": \"Kristina Toutanova\"}]}, {\"paperId\": \"753d2a35c9edf5dfcac4ef3a6adc993b657b01f0\", \"title\": \"Beyond Part Models: Person Retrieval with Refined Part Pooling\", \"abstract\": null, \"venue\": \"European Conference on Computer Vision\", \"year\": 2017, \"authors\": [{\"authorId\": \"2108935429\", \"name\": \"Yifan Sun\"}, {\"authorId\": \"144802394\", \"name\": \"Liang Zheng\"}, {\"authorId\": \"7179962\", \"name\": \"Yi Yang\"}, {\"authorId\": \"144876831\", \"name\": \"Q. Tian\"}, {\"authorId\": \"1678689\", \"name\": \"Shengjin Wang\"}]}, {\"paperId\": \"4fbe1e8f65f4c71565e8e6eb47c0c3a78a182bf3\", \"title\": \"Translation techniques in cross-language information retrieval\", \"abstract\": \"Cross-language information retrieval (CLIR) is an active sub-domain of information retrieval (IR). Like IR, CLIR is centered on the search for documents and for information contained within those documents. Unlike IR, CLIR must reconcile queries and documents that are written in different languages. The usual solution to this mismatch involves translating the query and/or the documents before performing the search. Translation is therefore a pivotal activity for CLIR engines. Over the last 15 years, the CLIR community has developed a wide range of techniques and models supporting free text translation. This article presents an overview of those techniques, with a special emphasis on recent developments.\", \"venue\": \"CSUR\", \"year\": 2012, \"authors\": [{\"authorId\": \"144066008\", \"name\": \"Dong Zhou\"}, {\"authorId\": \"1693495\", \"name\": \"M. Truran\"}, {\"authorId\": \"1683308\", \"name\": \"T. Brailsford\"}, {\"authorId\": \"1715807\", \"name\": \"V. Wade\"}, {\"authorId\": \"1710024\", \"name\": \"H. Ashman\"}]}, {\"paperId\": \"3f133e39f3fb543f25a1a75400b81c0d42c6a91c\", \"title\": \"Information Retrieval: Data Structures and Algorithms\", \"abstract\": \"An edited volume containing data structures and algorithms for information retrieved including a disk with examples written in C. For programmers and students interested in parsing text, automated indexing, its the first collection in book form of the basic data structures and algorithms that are critical to the storage and retrieval of documents.\", \"venue\": \"\", \"year\": 1992, \"authors\": [{\"authorId\": \"3163834\", \"name\": \"W. Frakes\"}, {\"authorId\": \"1389957009\", \"name\": \"R. Baeza-Yates\"}]}, {\"paperId\": \"7d986dac610e20441adb9161e5466c88932626e9\", \"title\": \"A study of smoothing methods for language models applied to information retrieval\", \"abstract\": \"Language modeling approaches to information retrieval are attractive and promising because they connect the problem of retrieval with that of language model estimation, which has been studied extensively in other application areas such as speech recognition. The basic idea of these approaches is to estimate a language model for each document, and to then rank documents by the likelihood of the query according to the estimated language model. A central issue in language model estimation is smoothing, the problem of adjusting the maximum likelihood estimator to compensate for data sparseness. In this article, we study the problem of language model smoothing and its influence on retrieval performance. We examine the sensitivity of retrieval performance to the smoothing parameters and compare several popular smoothing methods on different test collections. Experimental results show that not only is the retrieval performance generally sensitive to the smoothing parameters, but also the sensitivity pattern is affected by the query type, with performance being more sensitive to smoothing for verbose queries than for keyword queries. Verbose queries also generally require more aggressive smoothing to achieve optimal performance. This suggests that smoothing plays two different role---to make the estimated document language model more accurate and to \\\"explain\\\" the noninformative words in the query. In order to decouple these two distinct roles of smoothing, we propose a two-stage smoothing strategy, which yields better sensitivity patterns and facilitates the setting of smoothing parameters automatically. We further propose methods for estimating the smoothing parameters automatically. Evaluation on five different databases and four types of queries indicates that the two-stage smoothing method with the proposed parameter estimation methods consistently gives retrieval performance that is close to---or better than---the best results achieved using a single smoothing method and exhaustive parameter search on the test data.\", \"venue\": \"TOIS\", \"year\": 2004, \"authors\": [{\"authorId\": \"143869012\", \"name\": \"ChengXiang Zhai\"}, {\"authorId\": \"1739581\", \"name\": \"J. Lafferty\"}]}, {\"paperId\": \"da692ee969d9c33986196372c3f7cb87fa6b6f8f\", \"title\": \"Database resources of the National Center for Biotechnology Information\", \"abstract\": \"Abstract The National Center for Biotechnology Information (NCBI) provides a large suite of online resources for biological information and data, including the GenBank\\u00ae nucleic acid sequence database and the PubMed database of citations and abstracts for published life science journals. The Entrez system provides search and retrieval operations for most of these data from 39 distinct databases. The E-utilities serve as the programming interface for the Entrez system. Augmenting many of the Web applications are custom implementations of the BLAST program optimized to search specialized data sets. New resources released in the past year include PubMed Data Management, RefSeq Functional Elements, genome data download, variation services API, Magic-BLAST, QuickBLASTp, and Identical Protein Groups. Resources that were updated in the past year include the genome data viewer, a human genome resources page, Gene, virus variation, OSIRIS, and PubChem. All of these resources can be accessed through the NCBI home page at www.ncbi.nlm.nih.gov.\", \"venue\": \"Nucleic Acids Res.\", \"year\": 2017, \"authors\": [{\"authorId\": null, \"name\": \"Richa Tanya Jeff Dennis A Colleen Evan Devon J Rodney St Agarwala Barrett Beck Benson Bollin Bolton Bourexi\"}, {\"authorId\": \"144060663\", \"name\": \"R. Agarwala\"}, {\"authorId\": \"49588046\", \"name\": \"T. Barrett\"}, {\"authorId\": \"2065113442\", \"name\": \"J. Beck\"}, {\"authorId\": \"46415142\", \"name\": \"D. Benson\"}, {\"authorId\": \"81009968\", \"name\": \"Colleen J Bollin\"}, {\"authorId\": \"145600821\", \"name\": \"Evan E. Bolton\"}, {\"authorId\": \"84430451\", \"name\": \"Devon Bourexis\"}, {\"authorId\": \"145276593\", \"name\": \"J. R. Brister\"}, {\"authorId\": \"1807652\", \"name\": \"S. Bryant\"}, {\"authorId\": \"51025128\", \"name\": \"Kathi Canese\"}, {\"authorId\": \"119726475\", \"name\": \"Mark Cavanaugh\"}, {\"authorId\": \"81782113\", \"name\": \"Chad Charowhas\"}, {\"authorId\": \"144670517\", \"name\": \"Karen Clark\"}, {\"authorId\": \"11379483\", \"name\": \"I. Dondoshansky\"}, {\"authorId\": \"34189475\", \"name\": \"M. Feolo\"}, {\"authorId\": \"121737858\", \"name\": \"Lawrence Fitzpatrick\"}, {\"authorId\": \"37996742\", \"name\": \"Kathryn Funk\"}, {\"authorId\": \"2427813\", \"name\": \"L. Geer\"}, {\"authorId\": \"51412984\", \"name\": \"V. Gorelenkov\"}, {\"authorId\": \"133600931\", \"name\": \"Alan Graeff\"}, {\"authorId\": \"2966951\", \"name\": \"W. Hlavina\"}, {\"authorId\": \"2073870505\", \"name\": \"Brad Holmes\"}, {\"authorId\": \"2124469104\", \"name\": \"Mark Johnson\"}, {\"authorId\": \"8619885\", \"name\": \"B. Kattman\"}, {\"authorId\": \"79486219\", \"name\": \"Viatcheslav Khotomlianski\"}, {\"authorId\": \"47258944\", \"name\": \"Avi Kimchi\"}, {\"authorId\": \"48524102\", \"name\": \"Michael Kimelman\"}, {\"authorId\": \"2115838911\", \"name\": \"Masato Kimura\"}, {\"authorId\": \"50617031\", \"name\": \"P. Kitts\"}, {\"authorId\": \"50477132\", \"name\": \"W. Klimke\"}, {\"authorId\": \"14489952\", \"name\": \"A. Kotliarov\"}, {\"authorId\": \"2071710499\", \"name\": \"S. Krasnov\"}, {\"authorId\": \"48022505\", \"name\": \"A. Kuznetsov\"}, {\"authorId\": \"3218124\", \"name\": \"M. Landrum\"}, {\"authorId\": \"145385877\", \"name\": \"D. Landsman\"}, {\"authorId\": \"46172352\", \"name\": \"S. Lathrop\"}, {\"authorId\": \"2108441535\", \"name\": \"Jennifer M. Lee\"}, {\"authorId\": \"118034605\", \"name\": \"Carl Leubsdorf\"}, {\"authorId\": \"144202084\", \"name\": \"Zhiyong Lu\"}, {\"authorId\": \"34806045\", \"name\": \"T. Madden\"}, {\"authorId\": \"1398876428\", \"name\": \"A. Marchler-Bauer\"}, {\"authorId\": \"2325322\", \"name\": \"Adriana Malheiro\"}, {\"authorId\": \"2101820\", \"name\": \"Peter A. Meric\"}, {\"authorId\": \"1456397570\", \"name\": \"I. Karsch-Mizrachi\"}, {\"authorId\": \"84308998\", \"name\": \"Anatoly Mnev\"}, {\"authorId\": \"144308320\", \"name\": \"Terence D. Murphy\"}, {\"authorId\": \"51379817\", \"name\": \"R. Orris\"}, {\"authorId\": \"1968560\", \"name\": \"J. Ostell\"}, {\"authorId\": \"2064350009\", \"name\": \"Christopher O\\u2019Sullivan\"}, {\"authorId\": \"83723747\", \"name\": \"Vasuki Palanigobu\"}, {\"authorId\": \"2700929\", \"name\": \"A. Panchenko\"}, {\"authorId\": \"144205048\", \"name\": \"Lon Phan\"}, {\"authorId\": \"82921283\", \"name\": \"Borys Pierov\"}, {\"authorId\": \"1753253\", \"name\": \"K. Pruitt\"}, {\"authorId\": \"80249328\", \"name\": \"K. Rodarmer\"}, {\"authorId\": \"3011137\", \"name\": \"E. Sayers\"}, {\"authorId\": \"144863127\", \"name\": \"Valerie A. Schneider\"}, {\"authorId\": \"34637610\", \"name\": \"C. Schoch\"}, {\"authorId\": \"46481106\", \"name\": \"G. Schuler\"}, {\"authorId\": \"47019723\", \"name\": \"S. Sherry\"}, {\"authorId\": \"66416792\", \"name\": \"Karanjit Siyan\"}, {\"authorId\": \"47981624\", \"name\": \"Alexandra Soboleva\"}, {\"authorId\": \"78771575\", \"name\": \"Vladimir Soussov\"}, {\"authorId\": \"143680978\", \"name\": \"G. Starchenko\"}, {\"authorId\": \"1776968\", \"name\": \"T. Tatusova\"}, {\"authorId\": \"1401199158\", \"name\": \"F. Thibaud-Nissen\"}, {\"authorId\": \"5812910\", \"name\": \"K. Todorov\"}, {\"authorId\": \"5878244\", \"name\": \"B. Trawick\"}, {\"authorId\": \"51341623\", \"name\": \"D. Vakatov\"}, {\"authorId\": \"34515789\", \"name\": \"M. Ward\"}, {\"authorId\": \"2188116\", \"name\": \"E. Yaschenko\"}, {\"authorId\": \"10750188\", \"name\": \"A. Zasypkin\"}, {\"authorId\": \"48634577\", \"name\": \"Kerry Zbicz\"}]}, {\"paperId\": \"054080d32f41ec461758fdc382935a45b033836b\", \"title\": \"A study of smoothing methods for language models applied to Ad Hoc information retrieval\", \"abstract\": \"Language modeling approaches to information retrieval are attractive and promising because they connect the problem of retrieval with that of language model estimation, which has been studied extensively in other application areas such as speech recognition. The basic idea of these approaches is to estimate a language model for each document, and then rank documents by the likelihood of the query according to the estimated language model. A core problem in language model estimation is smoothing, which adjusts the maximum likelihood estimator so as to correct the inaccuracy due to data sparseness. In this paper, we study the problem of language model smoothing and its influence on retrieval performance. We examine the sensitivity of retrieval performance to the smoothing parameters and compare several popular smoothing methods on different test collections.\", \"venue\": \"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\", \"year\": 2001, \"authors\": [{\"authorId\": \"1736467\", \"name\": \"ChengXiang Zhai\"}, {\"authorId\": \"1739581\", \"name\": \"J. Lafferty\"}]}, {\"paperId\": \"3343c98d79d151635efa1f04797d358f9ebbdde7\", \"title\": \"Graph-based term weighting for information retrieval\", \"abstract\": null, \"venue\": \"Information retrieval (Boston)\", \"year\": 2012, \"authors\": [{\"authorId\": \"144367841\", \"name\": \"Roi Blanco\"}, {\"authorId\": \"1784800\", \"name\": \"C. Lioma\"}]}, {\"paperId\": \"09a2071b55a79243722d12f7939458ea27eb78e8\", \"title\": \"Modern Information Retrieval - the concepts and technology behind search, Second edition\", \"abstract\": \"Contents Preface Acknowledgements 1 Introduction 2 User Interfaces for Search by Marti Hearst 3 Modeling 4 Retrieval Evaluation 5 Relevance Feedback and Query Expansion 6 Documents: Languages & Properties with Gonzalo Navarro and Nivio Ziviani 7 Queries: Languages & Properties with Gonzalo Navarro 8 Text Classification with Marcos Gonccalves 9 Indexing and Searching with Gonzalo Navarro 10 Parallel and Distributed IR with Eric Brown 11 Web Retrieval with Yoelle Maarek 12 Web Crawling with Carlos Castillo 13 Structured Text Retrieval with Mounia Lalmas 14 Multimedia Information Retrieval by Dulce Poncele'on and Malcolm Slaney 15 Enterprise Search by David Hawking 16 Library Systems by Edie Rasmussen 17 Digital Libraries by Marcos Gonccalves A Open Source Search Engines with Christian Middleton B Biographies Bibliography Index\", \"venue\": \"\", \"year\": 2011, \"authors\": [{\"authorId\": \"1389957009\", \"name\": \"R. Baeza-Yates\"}, {\"authorId\": \"1396785771\", \"name\": \"B. Ribeiro-Neto\"}]}, {\"paperId\": \"69a5dba45472d34ba7246d6eb9065b5dad5ca51d\", \"title\": \"Information filtering and information retrieval: two sides of the same coin?\", \"abstract\": \"Information filtering systems are designed for unstructured or semistructured data, as opposed to database applications, which use very structured data. The systems also deal primarily with textual information, but they may also entail images, voice, video or other data types that are part of multimedia information systems. Information filtering systems also involve a large amount of data and streams of incoming data, whether broadcast from a remote source or sent directly by other sources. Filtering is based on descriptions of individual or group information preferences, or profiles, that typically represent long-term interests. Filtering also implies removal of data from an incoming stream rather than finding data in the stream; users see only the data that is extracted. Models of information retrieval and filtering, and lessons for filtering from retrieval research are presented.\", \"venue\": \"CACM\", \"year\": 1992, \"authors\": [{\"authorId\": \"2095083\", \"name\": \"N. Belkin\"}, {\"authorId\": \"144456145\", \"name\": \"W. Bruce Croft\"}]}, {\"paperId\": \"1af4aa8826fdee95a22fedbfc2f88b657af0ce08\", \"title\": \"Visual information retrieval\", \"abstract\": null, \"venue\": \"\", \"year\": 1999, \"authors\": [{\"authorId\": \"8196487\", \"name\": \"A. Bimbo\"}]}, {\"paperId\": \"1597a64f1738e49305a59d8822de65b390bc1dd9\", \"title\": \"Frontiers, challenges, and opportunities for information retrieval: Report from SWIRL 2012 the second strategic workshop on information retrieval in Lorne\", \"abstract\": \"During a three-day workshop in February 2012, 45 Information Retrieval researchers met to discuss long-range challenges and opportunities within the field. The result of the workshop is a diverse set of research directions, project ideas, and challenge areas. This report describes the workshop format, provides summaries of broad themes that emerged, includes brief descriptions of all the ideas, and provides detailed discussion of six proposals that were voted \\\"most interesting\\\" by the participants. Key themes include the need to: move beyond ranked lists of documents to support richer dialog and presentation, represent the context of search and searchers, provide richer support for information seeking, enable retrieval of a wide range of structured and unstructured content, and develop new evaluation methodologies.\", \"venue\": \"SIGF\", \"year\": 2012, \"authors\": [{\"authorId\": \"144890574\", \"name\": \"James Allan\"}, {\"authorId\": \"144456145\", \"name\": \"W. Bruce Croft\"}, {\"authorId\": \"144448479\", \"name\": \"Alistair Moffat\"}, {\"authorId\": \"144721996\", \"name\": \"M. Sanderson\"}]}, {\"paperId\": \"f1ca16dd768292fbcb4953c344fcee761705e8f8\", \"title\": \"The History of Information Retrieval Research\", \"abstract\": \"This paper describes a brief history of the research and development of information retrieval systems starting with the creation of electromechanical searching devices, through to the early adoption of computers to search for items that are relevant to a user's query. The advances achieved by information retrieval researchers from the 1950s through to the present day are detailed next, focusing on the process of locating relevant information. The paper closes with speculation on where the future of information retrieval lies.\", \"venue\": \"Proceedings of the IEEE\", \"year\": 2012, \"authors\": [{\"authorId\": \"144721996\", \"name\": \"M. Sanderson\"}, {\"authorId\": \"144456145\", \"name\": \"W. Bruce Croft\"}]}, {\"paperId\": \"1420ddbec40916173dc58be7af60790289893d84\", \"title\": \"Optimally Robust Private Information Retrieval\", \"abstract\": \"We give a protocol for multi-server information-theoretic private information retrieval which achieves the theoretical limit for Byzantine robustness. That is, the protocol can allow a client to successfully complete queries and identify server misbehavior in the presence of the maximum possible number of malicious servers. We have implemented our scheme and it is extremely fast in practice: up to thousands of times faster than previous work. We achieve these improvements by using decoding algorithms for error-correcting codes that take advantage of the practical scenario where the client is interested in multiple blocks of the database.\", \"venue\": \"USENIX Security Symposium\", \"year\": 2012, \"authors\": [{\"authorId\": \"2951641\", \"name\": \"Casey Devet\"}, {\"authorId\": \"34614659\", \"name\": \"I. Goldberg\"}, {\"authorId\": \"2842650\", \"name\": \"N. Heninger\"}]}, {\"paperId\": \"3a02f2823d39d2b1c91067032420fdf4290b0592\", \"title\": \"Data Fusion in Information Retrieval\", \"abstract\": null, \"venue\": \"Adaptation, Learning, and Optimization\", \"year\": 2012, \"authors\": [{\"authorId\": \"1684230\", \"name\": \"Shengli Wu\"}]}, {\"paperId\": \"2ff011cba4ecedf6b2c4501957dd53f208fbc019\", \"title\": \"Advances in Music Information Retrieval\", \"abstract\": null, \"venue\": \"Advances in Music Information Retrieval\", \"year\": 2012, \"authors\": [{\"authorId\": \"1742597\", \"name\": \"Z. Ras\"}, {\"authorId\": \"1760583\", \"name\": \"Alicja Wieczorkowska\"}]}, {\"paperId\": \"271afa1d279c340debdd6241a7cce61220fb5fd9\", \"title\": \"Information retrieval model: A social network extraction perspective\", \"abstract\": \"Future Information Retrieval, especially in connection with the internet, will incorporate the content descriptions that are generated with social network extraction technologies and preferably incorporate the probability theory for assigning the semantic. Although there is an increasing interest about social network extraction, but a little of them has a significant impact to information retrieval. Therefore this paper proposes a model of information retrieval from the social network extraction.\", \"venue\": \"2012 International Conference on Information Retrieval & Knowledge Management\", \"year\": 2012, \"authors\": [{\"authorId\": \"144333296\", \"name\": \"M. K. Nasution\"}, {\"authorId\": \"2480890\", \"name\": \"S. Noah\"}]}, {\"paperId\": \"38de590b8290c7628df38d010aef7dbb153f85da\", \"title\": \"Crowdsourcing for information retrieval\", \"abstract\": \"The 2nd SIGIR Workshop on Crowdsourcing for Information Retrieval (CIR 2011) was held on July 28, 2011 in Beijing, China, in conjunction with the 34th Annual ACM SIGIR Conference1. The workshop brought together researchers and practitioners to disseminate recent advances in theory, empirical methods, and novel applications of crowdsourcing for information retrieval (IR). The workshop program included three invited talks, a panel discussion entitled Beyond the Lab: State-of-the-Art and Open Challenges in Practical Crowdsourcing, and presentation of nine refereed research papers and one demonstration paper. A Best Paper Award, sponored by Microsoft Bing, was awarded to Jun Wang and Bei Yu for their paper entitled Labeling Images with Queries: A Recall-based Image Retrieval Game Approach. A Crowdsourcing Challenge contest was also announced prior to the workshop, sponsored by CrowdFlower. The contest offered both seed funding and advanced technical support for the winner to use CrowdFlower's services for innovative work. Workshop organizers selected Mark Smucker as the winner based on his proposal entitled: The Crowd vs. the Lab: A Comparison of Crowd-Sourced and University Laboratory Participant Behavior. Proceedings of the workshop are available online2 [15].\", \"venue\": \"SIGF\", \"year\": 2012, \"authors\": [{\"authorId\": \"1747771\", \"name\": \"Matthew Lease\"}, {\"authorId\": \"49724730\", \"name\": \"Emine Yilmaz\"}]}, {\"paperId\": \"c029baf196f33050ceea9ecbf90f054fd5654277\", \"title\": \"Search Engines - Information Retrieval in Practice\", \"abstract\": \"KEY BENEFIT: Written by a leader in the field of information retrieval, this text provides the background and tools needed to evaluate, compare and modify search engines. KEY TOPICS: Coverage of the underlying IR and mathematical models reinforce key concepts. Numerous programming exercises make extensive use of Galago, a Java-based open source search engine. MARKET: A valuable tool for search engine and information retrieval professionals.\", \"venue\": \"\", \"year\": 2009, \"authors\": [{\"authorId\": \"144456145\", \"name\": \"W. Bruce Croft\"}, {\"authorId\": \"1680617\", \"name\": \"Donald Metzler\"}, {\"authorId\": \"2985957\", \"name\": \"Trevor Strohman\"}]}, {\"paperId\": \"c17289ea3d4f1d621fddb807870a802b3220e2b2\", \"title\": \"Information retrieval systems, information retrieval apparatus, information retrieval method, and a program\", \"abstract\": null, \"venue\": \"\", \"year\": 2013, \"authors\": [{\"authorId\": \"52421883\", \"name\": \"\\u6df3 \\u5bcc\\u58eb\\u672c\"}, {\"authorId\": \"71395198\", \"name\": \"\\u8aa0\\u4e4b \\u91ce\\u4e2d\"}, {\"authorId\": \"66735564\", \"name\": \"\\u91ce\\u4e2d \\u8aa0\\u4e4b\"}, {\"authorId\": \"73666186\", \"name\": \"\\u88d5 \\u52dd\\u5009\"}, {\"authorId\": \"72708182\", \"name\": \"\\u52dd\\u5009 \\u88d5\"}]}, {\"paperId\": \"2175dafeb0a9e6965da72bc0849111eff0da16f1\", \"title\": \"Multilingual Information Retrieval\", \"abstract\": null, \"venue\": \"Springer Berlin Heidelberg\", \"year\": 2012, \"authors\": [{\"authorId\": \"144423157\", \"name\": \"C. Peters\"}, {\"authorId\": \"3075644\", \"name\": \"Martin Braschler\"}, {\"authorId\": \"1704149\", \"name\": \"Paul D. Clough\"}]}, {\"paperId\": \"048b265a90b369322c55711eb42c1dbd089856c9\", \"title\": \"Deep Supervised Hashing for Fast Image Retrieval\", \"abstract\": null, \"venue\": \"Computer Vision and Pattern Recognition\", \"year\": 2016, \"authors\": [{\"authorId\": \"3035576\", \"name\": \"Haomiao Liu\"}, {\"authorId\": \"2108681349\", \"name\": \"Ruiping Wang\"}, {\"authorId\": \"145455919\", \"name\": \"S. Shan\"}, {\"authorId\": \"46772547\", \"name\": \"Xilin Chen\"}]}, {\"paperId\": \"da457a529ee78d44f1aa07fe1960657f6cec7957\", \"title\": \"Phase Retrieval via Wirtinger Flow: Theory and Algorithms\", \"abstract\": \"We study the problem of recovering the phase from magnitude measurements; specifically, we wish to reconstruct a complex-valued signal x \\u2208 \\u2102n about which we have phaseless samples of the form yr = |\\u2329ar, x\\u232a|2, r = 1, ..., m (knowledge of the phase of these samples would yield a linear system). This paper develops a nonconvex formulation of the phase retrieval problem as well as a concrete solution algorithm. In a nutshell, this algorithm starts with a careful initialization obtained by means of a spectral method, and then refines this initial estimate by iteratively applying novel update rules, which have low computational complexity, much like in a gradient descent scheme. The main contribution is that this algorithm is shown to rigorously allow the exact retrieval of phase information from a nearly minimal number of random measurements. Indeed, the sequence of successive iterates provably converges to the solution at a geometric rate so that the proposed scheme is efficient both in terms of computational and data resources. In theory, a variation on this scheme leads to a near-linear time algorithm for a physically realizable model based on coded diffraction patterns. We illustrate the effectiveness of our methods with various experiments on image data. Underlying our analysis are insights for the analysis of nonconvex optimization schemes that may have implications for computational problems beyond phase retrieval.\", \"venue\": \"IEEE Transactions on Information Theory\", \"year\": 2014, \"authors\": [{\"authorId\": \"2006869\", \"name\": \"E. Cand\\u00e8s\"}, {\"authorId\": \"2118899110\", \"name\": \"Xiaodong Li\"}, {\"authorId\": \"2766123\", \"name\": \"M. Soltanolkotabi\"}]}, {\"paperId\": \"2989b07819dfd279222a3755d3b7862f1a1a7f53\", \"title\": \"Texture Features for Browsing and Retrieval of Image Data\", \"abstract\": \"Image content based retrieval is emerging as an important research area with application to digital libraries and multimedia databases. The focus of this paper is on the image processing aspects and in particular using texture information for browsing and retrieval of large image data. We propose the use of Gabor wavelet features for texture analysis and provide a comprehensive experimental evaluation. Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy. An application to browsing large air photos is illustrated.\", \"venue\": \"IEEE Transactions on Pattern Analysis and Machine Intelligence\", \"year\": 1996, \"authors\": [{\"authorId\": \"50591689\", \"name\": \"B. S. Manjunath\"}, {\"authorId\": \"1712167\", \"name\": \"Wei-Ying Ma\"}]}, {\"paperId\": \"26f2e89f5585cf2ec4c0cdcd4ec4264d5726b07e\", \"title\": \"Research and Development in Information Retrieval\", \"abstract\": null, \"venue\": \"Lecture Notes in Computer Science\", \"year\": 1982, \"authors\": [{\"authorId\": \"1797808\", \"name\": \"G. Salton\"}, {\"authorId\": \"2114660236\", \"name\": \"H. Schneider\"}]}, {\"paperId\": \"15004aadabd967ac722a28a9c3bb39cf5bc32605\", \"title\": \"Novelty and diversity in information retrieval evaluation\", \"abstract\": \"Evaluation measures act as objective functions to be optimized by information retrieval systems. Such objective functions must accurately reflect user requirements, particularly when tuning IR systems and learning ranking functions. Ambiguity in queries and redundancy in retrieved documents are poorly reflected by current evaluation measures. In this paper, we present a framework for evaluation that systematically rewards novelty and diversity. We develop this framework into a specific evaluation measure, based on cumulative gain. We demonstrate the feasibility of our approach using a test collection based on the TREC question answering track.\", \"venue\": \"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\", \"year\": 2008, \"authors\": [{\"authorId\": \"1751287\", \"name\": \"C. Clarke\"}, {\"authorId\": \"2690669\", \"name\": \"M. Kolla\"}, {\"authorId\": \"3114123\", \"name\": \"G. Cormack\"}, {\"authorId\": \"1712417\", \"name\": \"Olga Vechtomova\"}, {\"authorId\": \"1715458\", \"name\": \"Azin Ashkan\"}, {\"authorId\": \"2178188\", \"name\": \"Stefan B\\u00fcttcher\"}, {\"authorId\": \"48509200\", \"name\": \"Ian MacKinnon\"}]}, {\"paperId\": \"18e93fa7d408e9596992f3d63155cb92827839a4\", \"title\": \"Adapting boosting for information retrieval measures\", \"abstract\": null, \"venue\": \"Information retrieval (Boston)\", \"year\": 2010, \"authors\": [{\"authorId\": \"2108728368\", \"name\": \"Qiang Wu\"}, {\"authorId\": \"2676309\", \"name\": \"C. Burges\"}, {\"authorId\": \"1742466\", \"name\": \"K. Svore\"}, {\"authorId\": \"1800422\", \"name\": \"Jianfeng Gao\"}]}, {\"paperId\": \"6fb1955992c1ef5147d07916bf0affaf0139f32a\", \"title\": \"Terrier : A High Performance and Scalable Information Retrieval Platform\", \"abstract\": \"In this paper, we describe Terrier, a high performance and scalable search engine that allows the rapid development of large-scale retrieval applications. We focus on the opensource version of the software, which provides a comprehensive, flexible, robust, and transparent test-bed platform for research and experimentation in Information Retrieval (IR).\", \"venue\": \"\", \"year\": null, \"authors\": [{\"authorId\": \"1698205\", \"name\": \"I. Ounis\"}, {\"authorId\": \"1743641\", \"name\": \"G. Amati\"}, {\"authorId\": \"1798301\", \"name\": \"Vassilis Plachouras\"}, {\"authorId\": \"40368776\", \"name\": \"Ben He\"}, {\"authorId\": \"145434248\", \"name\": \"C. Macdonald\"}, {\"authorId\": \"1784800\", \"name\": \"C. Lioma\"}]}]}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztRBjBrW7NkC"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_51UZie57NkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbbd263-72ff-4647-bea5-d4e566a05759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.8/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.8/dist-packages (from tweepy) (2.25.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "# To interact with the twitter I have installed the package tweepy\n",
        "!pip install tweepy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I have imported all the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "import requests\n",
        "import json\n"
      ],
      "metadata": {
        "id": "PyEPjxw4pODK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I have taken the Consumer Key, Consumer Secret, Access Key and Access Secret from the samples\n",
        "CK ='u7L1lnR7HN85dn1qnTFO1cegb'\n",
        "CS = 'QN1JrEmit2To46ZcwWAT4aI5QGWZXWRDDUPnMCWV5M66SFc8wT'\n",
        "AK = '1144377060036620294-BSEicX3zH7hIhksbNZV9mrWFwa07cO'\n",
        "AS = 'gxWMOodDq1nQAjix9mHEOUSAtgE7XH5ctHInm0XRslJce'"
      ],
      "metadata": {
        "id": "fzrBMBnYqjRn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Authorising and Initializing\n",
        "auth = tweepy.OAuthHandler(CK, CS)\n",
        "auth.set_access_token(AK, AS)\n",
        "api_auth = tweepy.API(auth,wait_on_rate_limit=True)"
      ],
      "metadata": {
        "id": "-bt9jPYSqBsZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I am trying to gather the tweets of Rohit\n",
        "user_name =\"Rohit\""
      ],
      "metadata": {
        "id": "SpQO-eYzqMbj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I am going to collect 1234 posts posted by Rohit from Twitter\n",
        "t = tweepy.Cursor(api_auth.user_timeline,id=user_name).items(1234)\n",
        "#Here I am going to collect the user name, posted time and text of each\n",
        "tweets_df = [[user_name ,tweet.created_at, tweet.text] for tweet in t]\n",
        "#Here I am going to create a data frame with the above mentioned fields\n",
        "df = pd.DataFrame(tweets_df)\n",
        "#Naming the colums of the data drame\n",
        "df.columns=['User_name','Posted time','Text']\n",
        "#Printing the data frame\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8aqqHLxBqMe3",
        "outputId": "eaaaff40-b901-4e8c-d523-92a14918667f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     User_name         Posted time  \\\n",
              "0        Rohit 2022-07-12 19:02:23   \n",
              "1        Rohit 2020-03-04 20:39:36   \n",
              "2        Rohit 2020-01-09 02:51:12   \n",
              "3        Rohit 2019-07-16 17:01:37   \n",
              "4        Rohit 2019-05-02 20:51:18   \n",
              "...        ...                 ...   \n",
              "1229     Rohit 2013-02-07 14:12:40   \n",
              "1230     Rohit 2013-02-07 14:12:15   \n",
              "1231     Rohit 2013-02-06 14:40:29   \n",
              "1232     Rohit 2013-02-04 10:58:12   \n",
              "1233     Rohit 2013-02-04 03:09:57   \n",
              "\n",
              "                                                   Text  \n",
              "0     RT @sentenai: Sentenai is excited to work with...  \n",
              "1     RT @NSIN_us: This week our #52WeeksOfInnovatio...  \n",
              "2     RT @austinfish: Hot damn, I am so excited to h...  \n",
              "3     RT @austinfish: 1/3 I’m tired of hearing peopl...  \n",
              "4     @jeffseibert @Wayne @digits wait, shouldn’t yo...  \n",
              "...                                                 ...  \n",
              "1229  @hunterwalk congrats on the awesome news, grea...  \n",
              "1230  @jeffseibert dude heard them refer to your new...  \n",
              "1231  @aaron0 ugh it’s killing me might be faster to...  \n",
              "1232  It’s only about once a week I’m asked if I’m r...  \n",
              "1233  RT @capndesign: If this goes to a shootout, Ra...  \n",
              "\n",
              "[1234 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44b09549-97c4-4472-96cf-c8b4cd9387a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_name</th>\n",
              "      <th>Posted time</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2022-07-12 19:02:23</td>\n",
              "      <td>RT @sentenai: Sentenai is excited to work with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2020-03-04 20:39:36</td>\n",
              "      <td>RT @NSIN_us: This week our #52WeeksOfInnovatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2020-01-09 02:51:12</td>\n",
              "      <td>RT @austinfish: Hot damn, I am so excited to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2019-07-16 17:01:37</td>\n",
              "      <td>RT @austinfish: 1/3 I’m tired of hearing peopl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2019-05-02 20:51:18</td>\n",
              "      <td>@jeffseibert @Wayne @digits wait, shouldn’t yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2013-02-07 14:12:40</td>\n",
              "      <td>@hunterwalk congrats on the awesome news, grea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2013-02-07 14:12:15</td>\n",
              "      <td>@jeffseibert dude heard them refer to your new...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2013-02-06 14:40:29</td>\n",
              "      <td>@aaron0 ugh it’s killing me might be faster to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2013-02-04 10:58:12</td>\n",
              "      <td>It’s only about once a week I’m asked if I’m r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>Rohit</td>\n",
              "      <td>2013-02-04 03:09:57</td>\n",
              "      <td>RT @capndesign: If this goes to a shootout, Ra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1234 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44b09549-97c4-4472-96cf-c8b4cd9387a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44b09549-97c4-4472-96cf-c8b4cd9387a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44b09549-97c4-4472-96cf-c8b4cd9387a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}